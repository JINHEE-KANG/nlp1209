{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 개선판 word2vec 학습모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_layers import  Embedding, EmbeddingDot, NegativeSamplingLoss, Adam, Trainer\n",
    "from mynlp import  preprocess, most_similar, create_contexts_target \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)  # Embedding 계층 사용\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "\n",
    "        # 모든 가중치와 기울기를 배열에 모은다.\n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "929589\n"
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "import pickle\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "window_size = 5\n",
    "# window_size = 2\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 10  # 10회 이상\n",
    "\n",
    "# 데이터 읽기\n",
    "# 전체 데이터 모두 사용시  # 전체 데이터로 epoch 10회 학습 ==> '약 10시간 소요'\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "print(vocab_size)\n",
    "print(len(word_to_id))\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5276\n",
      "5276\n",
      "5276\n"
     ]
    }
   ],
   "source": [
    "# PTB 데이터 중 일부만 사용시\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "corpus_size = 50000\n",
    "corpus = corpus[:corpus_size]\n",
    "\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "temp1,temp2 = {},{}\n",
    "for k in range(vocab_size):\n",
    "    word1= list(word_to_id.keys())[k]    \n",
    "    id1 = list(word_to_id.values())[k] \n",
    "    temp1[word1] = id1\n",
    "    \n",
    "    word2= list(id_to_word.keys())[k]    \n",
    "    id2 = list(id_to_word.values())[k] \n",
    "    temp2[word2] = id2\n",
    "    \n",
    "word_to_id = temp1\n",
    "id_to_word =temp2\n",
    "\n",
    "print(len(corpus))\n",
    "print(vocab_size)\n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 499 | 시간 0[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 21 / 499 | 시간 1[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 41 / 499 | 시간 1[s] | 손실 4.15\n",
      "| 에폭 1 |  반복 61 / 499 | 시간 2[s] | 손실 4.11\n",
      "| 에폭 1 |  반복 81 / 499 | 시간 3[s] | 손실 4.01\n",
      "| 에폭 1 |  반복 101 / 499 | 시간 5[s] | 손실 3.85\n",
      "| 에폭 1 |  반복 121 / 499 | 시간 6[s] | 손실 3.67\n",
      "| 에폭 1 |  반복 141 / 499 | 시간 7[s] | 손실 3.50\n",
      "| 에폭 1 |  반복 161 / 499 | 시간 8[s] | 손실 3.32\n",
      "| 에폭 1 |  반복 181 / 499 | 시간 9[s] | 손실 3.20\n",
      "| 에폭 1 |  반복 201 / 499 | 시간 10[s] | 손실 3.10\n",
      "| 에폭 1 |  반복 221 / 499 | 시간 11[s] | 손실 3.01\n",
      "| 에폭 1 |  반복 241 / 499 | 시간 12[s] | 손실 2.94\n",
      "| 에폭 1 |  반복 261 / 499 | 시간 13[s] | 손실 2.87\n",
      "| 에폭 1 |  반복 281 / 499 | 시간 14[s] | 손실 2.84\n",
      "| 에폭 1 |  반복 301 / 499 | 시간 15[s] | 손실 2.79\n",
      "| 에폭 1 |  반복 321 / 499 | 시간 16[s] | 손실 2.78\n",
      "| 에폭 1 |  반복 341 / 499 | 시간 17[s] | 손실 2.76\n",
      "| 에폭 1 |  반복 361 / 499 | 시간 18[s] | 손실 2.73\n",
      "| 에폭 1 |  반복 381 / 499 | 시간 19[s] | 손실 2.72\n",
      "| 에폭 1 |  반복 401 / 499 | 시간 21[s] | 손실 2.71\n",
      "| 에폭 1 |  반복 421 / 499 | 시간 22[s] | 손실 2.69\n",
      "| 에폭 1 |  반복 441 / 499 | 시간 23[s] | 손실 2.70\n",
      "| 에폭 1 |  반복 461 / 499 | 시간 24[s] | 손실 2.68\n",
      "| 에폭 1 |  반복 481 / 499 | 시간 25[s] | 손실 2.67\n",
      "| 에폭 2 |  반복 1 / 499 | 시간 26[s] | 손실 2.68\n",
      "| 에폭 2 |  반복 21 / 499 | 시간 27[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 41 / 499 | 시간 28[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 61 / 499 | 시간 29[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 81 / 499 | 시간 30[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 101 / 499 | 시간 31[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 121 / 499 | 시간 32[s] | 손실 2.65\n",
      "| 에폭 2 |  반복 141 / 499 | 시간 33[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 161 / 499 | 시간 34[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 181 / 499 | 시간 35[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 201 / 499 | 시간 36[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 221 / 499 | 시간 38[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 241 / 499 | 시간 39[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 261 / 499 | 시간 41[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 281 / 499 | 시간 42[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 301 / 499 | 시간 43[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 321 / 499 | 시간 44[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 341 / 499 | 시간 45[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 361 / 499 | 시간 46[s] | 손실 2.60\n",
      "| 에폭 2 |  반복 381 / 499 | 시간 47[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 401 / 499 | 시간 48[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 421 / 499 | 시간 49[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 441 / 499 | 시간 50[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 461 / 499 | 시간 51[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 481 / 499 | 시간 52[s] | 손실 2.62\n",
      "| 에폭 3 |  반복 1 / 499 | 시간 53[s] | 손실 2.63\n",
      "| 에폭 3 |  반복 21 / 499 | 시간 54[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 41 / 499 | 시간 55[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 61 / 499 | 시간 56[s] | 손실 2.54\n",
      "| 에폭 3 |  반복 81 / 499 | 시간 58[s] | 손실 2.56\n",
      "| 에폭 3 |  반복 101 / 499 | 시간 59[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 121 / 499 | 시간 60[s] | 손실 2.54\n",
      "| 에폭 3 |  반복 141 / 499 | 시간 61[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 161 / 499 | 시간 62[s] | 손실 2.60\n",
      "| 에폭 3 |  반복 181 / 499 | 시간 63[s] | 손실 2.60\n",
      "| 에폭 3 |  반복 201 / 499 | 시간 64[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 221 / 499 | 시간 66[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 241 / 499 | 시간 67[s] | 손실 2.59\n",
      "| 에폭 3 |  반복 261 / 499 | 시간 68[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 281 / 499 | 시간 69[s] | 손실 2.59\n",
      "| 에폭 3 |  반복 301 / 499 | 시간 70[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 321 / 499 | 시간 71[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 341 / 499 | 시간 72[s] | 손실 2.59\n",
      "| 에폭 3 |  반복 361 / 499 | 시간 73[s] | 손실 2.60\n",
      "| 에폭 3 |  반복 381 / 499 | 시간 74[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 401 / 499 | 시간 75[s] | 손실 2.56\n",
      "| 에폭 3 |  반복 421 / 499 | 시간 76[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 441 / 499 | 시간 78[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 461 / 499 | 시간 79[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 481 / 499 | 시간 80[s] | 손실 2.56\n",
      "| 에폭 4 |  반복 1 / 499 | 시간 81[s] | 손실 2.57\n",
      "| 에폭 4 |  반복 21 / 499 | 시간 82[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 41 / 499 | 시간 83[s] | 손실 2.51\n",
      "| 에폭 4 |  반복 61 / 499 | 시간 84[s] | 손실 2.54\n",
      "| 에폭 4 |  반복 81 / 499 | 시간 85[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 101 / 499 | 시간 86[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 121 / 499 | 시간 87[s] | 손실 2.50\n",
      "| 에폭 4 |  반복 141 / 499 | 시간 88[s] | 손실 2.53\n",
      "| 에폭 4 |  반복 161 / 499 | 시간 89[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 181 / 499 | 시간 90[s] | 손실 2.53\n",
      "| 에폭 4 |  반복 201 / 499 | 시간 91[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 221 / 499 | 시간 92[s] | 손실 2.53\n",
      "| 에폭 4 |  반복 241 / 499 | 시간 93[s] | 손실 2.53\n",
      "| 에폭 4 |  반복 261 / 499 | 시간 95[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 281 / 499 | 시간 96[s] | 손실 2.54\n",
      "| 에폭 4 |  반복 301 / 499 | 시간 97[s] | 손실 2.51\n",
      "| 에폭 4 |  반복 321 / 499 | 시간 98[s] | 손실 2.53\n",
      "| 에폭 4 |  반복 341 / 499 | 시간 99[s] | 손실 2.55\n",
      "| 에폭 4 |  반복 361 / 499 | 시간 100[s] | 손실 2.56\n",
      "| 에폭 4 |  반복 381 / 499 | 시간 101[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 401 / 499 | 시간 102[s] | 손실 2.54\n",
      "| 에폭 4 |  반복 421 / 499 | 시간 103[s] | 손실 2.55\n",
      "| 에폭 4 |  반복 441 / 499 | 시간 104[s] | 손실 2.57\n",
      "| 에폭 4 |  반복 461 / 499 | 시간 105[s] | 손실 2.56\n",
      "| 에폭 4 |  반복 481 / 499 | 시간 106[s] | 손실 2.53\n",
      "| 에폭 5 |  반복 1 / 499 | 시간 107[s] | 손실 2.55\n",
      "| 에폭 5 |  반복 21 / 499 | 시간 108[s] | 손실 2.48\n",
      "| 에폭 5 |  반복 41 / 499 | 시간 109[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 61 / 499 | 시간 110[s] | 손실 2.48\n",
      "| 에폭 5 |  반복 81 / 499 | 시간 112[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 101 / 499 | 시간 113[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 121 / 499 | 시간 115[s] | 손실 2.52\n",
      "| 에폭 5 |  반복 141 / 499 | 시간 116[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 161 / 499 | 시간 117[s] | 손실 2.47\n",
      "| 에폭 5 |  반복 181 / 499 | 시간 118[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 201 / 499 | 시간 119[s] | 손실 2.47\n",
      "| 에폭 5 |  반복 221 / 499 | 시간 120[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 241 / 499 | 시간 121[s] | 손실 2.48\n",
      "| 에폭 5 |  반복 261 / 499 | 시간 122[s] | 손실 2.52\n",
      "| 에폭 5 |  반복 281 / 499 | 시간 123[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 301 / 499 | 시간 124[s] | 손실 2.49\n",
      "| 에폭 5 |  반복 321 / 499 | 시간 126[s] | 손실 2.48\n",
      "| 에폭 5 |  반복 341 / 499 | 시간 127[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 361 / 499 | 시간 128[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 381 / 499 | 시간 129[s] | 손실 2.52\n",
      "| 에폭 5 |  반복 401 / 499 | 시간 130[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 421 / 499 | 시간 131[s] | 손실 2.53\n",
      "| 에폭 5 |  반복 441 / 499 | 시간 132[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 461 / 499 | 시간 133[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 481 / 499 | 시간 134[s] | 손실 2.52\n",
      "| 에폭 6 |  반복 1 / 499 | 시간 135[s] | 손실 2.50\n",
      "| 에폭 6 |  반복 21 / 499 | 시간 137[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 41 / 499 | 시간 138[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 61 / 499 | 시간 139[s] | 손실 2.43\n",
      "| 에폭 6 |  반복 81 / 499 | 시간 140[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 101 / 499 | 시간 141[s] | 손실 2.43\n",
      "| 에폭 6 |  반복 121 / 499 | 시간 142[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 141 / 499 | 시간 143[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 161 / 499 | 시간 144[s] | 손실 2.44\n",
      "| 에폭 6 |  반복 181 / 499 | 시간 145[s] | 손실 2.49\n",
      "| 에폭 6 |  반복 201 / 499 | 시간 146[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 221 / 499 | 시간 147[s] | 손실 2.48\n",
      "| 에폭 6 |  반복 241 / 499 | 시간 149[s] | 손실 2.43\n",
      "| 에폭 6 |  반복 261 / 499 | 시간 150[s] | 손실 2.48\n",
      "| 에폭 6 |  반복 281 / 499 | 시간 151[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 301 / 499 | 시간 152[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 321 / 499 | 시간 153[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 341 / 499 | 시간 154[s] | 손실 2.48\n",
      "| 에폭 6 |  반복 361 / 499 | 시간 155[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 381 / 499 | 시간 156[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 401 / 499 | 시간 157[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 421 / 499 | 시간 158[s] | 손실 2.49\n",
      "| 에폭 6 |  반복 441 / 499 | 시간 159[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 461 / 499 | 시간 160[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 481 / 499 | 시간 160[s] | 손실 2.43\n",
      "| 에폭 7 |  반복 1 / 499 | 시간 161[s] | 손실 2.45\n",
      "| 에폭 7 |  반복 21 / 499 | 시간 162[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 41 / 499 | 시간 163[s] | 손실 2.43\n",
      "| 에폭 7 |  반복 61 / 499 | 시간 164[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 81 / 499 | 시간 165[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 101 / 499 | 시간 166[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 121 / 499 | 시간 168[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 141 / 499 | 시간 169[s] | 손실 2.37\n",
      "| 에폭 7 |  반복 161 / 499 | 시간 170[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 181 / 499 | 시간 171[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 201 / 499 | 시간 172[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 221 / 499 | 시간 173[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 241 / 499 | 시간 174[s] | 손실 2.39\n",
      "| 에폭 7 |  반복 261 / 499 | 시간 175[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 281 / 499 | 시간 176[s] | 손실 2.38\n",
      "| 에폭 7 |  반복 301 / 499 | 시간 177[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 321 / 499 | 시간 178[s] | 손실 2.44\n",
      "| 에폭 7 |  반복 341 / 499 | 시간 179[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 361 / 499 | 시간 180[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 381 / 499 | 시간 181[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 401 / 499 | 시간 182[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 421 / 499 | 시간 183[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 441 / 499 | 시간 184[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 461 / 499 | 시간 185[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 481 / 499 | 시간 186[s] | 손실 2.40\n",
      "| 에폭 8 |  반복 1 / 499 | 시간 187[s] | 손실 2.37\n",
      "| 에폭 8 |  반복 21 / 499 | 시간 189[s] | 손실 2.36\n",
      "| 에폭 8 |  반복 41 / 499 | 시간 190[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 61 / 499 | 시간 191[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 81 / 499 | 시간 192[s] | 손실 2.38\n",
      "| 에폭 8 |  반복 101 / 499 | 시간 193[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 121 / 499 | 시간 195[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 141 / 499 | 시간 196[s] | 손실 2.37\n",
      "| 에폭 8 |  반복 161 / 499 | 시간 197[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 181 / 499 | 시간 198[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 201 / 499 | 시간 199[s] | 손실 2.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 8 |  반복 221 / 499 | 시간 200[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 241 / 499 | 시간 201[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 261 / 499 | 시간 202[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 281 / 499 | 시간 203[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 301 / 499 | 시간 204[s] | 손실 2.37\n",
      "| 에폭 8 |  반복 321 / 499 | 시간 205[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 341 / 499 | 시간 206[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 361 / 499 | 시간 207[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 381 / 499 | 시간 208[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 401 / 499 | 시간 209[s] | 손실 2.32\n",
      "| 에폭 8 |  반복 421 / 499 | 시간 210[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 441 / 499 | 시간 211[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 461 / 499 | 시간 212[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 481 / 499 | 시간 213[s] | 손실 2.34\n",
      "| 에폭 9 |  반복 1 / 499 | 시간 214[s] | 손실 2.34\n",
      "| 에폭 9 |  반복 21 / 499 | 시간 215[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 41 / 499 | 시간 216[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 61 / 499 | 시간 217[s] | 손실 2.27\n",
      "| 에폭 9 |  반복 81 / 499 | 시간 218[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 101 / 499 | 시간 219[s] | 손실 2.27\n",
      "| 에폭 9 |  반복 121 / 499 | 시간 220[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 141 / 499 | 시간 221[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 161 / 499 | 시간 222[s] | 손실 2.29\n",
      "| 에폭 9 |  반복 181 / 499 | 시간 223[s] | 손실 2.29\n",
      "| 에폭 9 |  반복 201 / 499 | 시간 225[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 221 / 499 | 시간 226[s] | 손실 2.30\n",
      "| 에폭 9 |  반복 241 / 499 | 시간 227[s] | 손실 2.31\n",
      "| 에폭 9 |  반복 261 / 499 | 시간 228[s] | 손실 2.27\n",
      "| 에폭 9 |  반복 281 / 499 | 시간 229[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 301 / 499 | 시간 230[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 321 / 499 | 시간 231[s] | 손실 2.30\n",
      "| 에폭 9 |  반복 341 / 499 | 시간 232[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 361 / 499 | 시간 233[s] | 손실 2.27\n",
      "| 에폭 9 |  반복 381 / 499 | 시간 234[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 401 / 499 | 시간 235[s] | 손실 2.27\n",
      "| 에폭 9 |  반복 421 / 499 | 시간 236[s] | 손실 2.24\n",
      "| 에폭 9 |  반복 441 / 499 | 시간 237[s] | 손실 2.30\n",
      "| 에폭 9 |  반복 461 / 499 | 시간 238[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 481 / 499 | 시간 239[s] | 손실 2.30\n",
      "| 에폭 10 |  반복 1 / 499 | 시간 240[s] | 손실 2.30\n",
      "| 에폭 10 |  반복 21 / 499 | 시간 241[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 41 / 499 | 시간 242[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 61 / 499 | 시간 243[s] | 손실 2.19\n",
      "| 에폭 10 |  반복 81 / 499 | 시간 244[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 101 / 499 | 시간 245[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 121 / 499 | 시간 246[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 141 / 499 | 시간 247[s] | 손실 2.22\n",
      "| 에폭 10 |  반복 161 / 499 | 시간 248[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 181 / 499 | 시간 249[s] | 손실 2.17\n",
      "| 에폭 10 |  반복 201 / 499 | 시간 250[s] | 손실 2.19\n",
      "| 에폭 10 |  반복 221 / 499 | 시간 251[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 241 / 499 | 시간 252[s] | 손실 2.19\n",
      "| 에폭 10 |  반복 261 / 499 | 시간 253[s] | 손실 2.24\n",
      "| 에폭 10 |  반복 281 / 499 | 시간 254[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 301 / 499 | 시간 255[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 321 / 499 | 시간 256[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 341 / 499 | 시간 257[s] | 손실 2.24\n",
      "| 에폭 10 |  반복 361 / 499 | 시간 258[s] | 손실 2.24\n",
      "| 에폭 10 |  반복 381 / 499 | 시간 259[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 401 / 499 | 시간 260[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 421 / 499 | 시간 261[s] | 손실 2.22\n",
      "| 에폭 10 |  반복 441 / 499 | 시간 262[s] | 손실 2.19\n",
      "| 에폭 10 |  반복 461 / 499 | 시간 263[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 481 / 499 | 시간 264[s] | 손실 2.22\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5dn48e+dyWRfIQlL2PcdlyAggoioIK7YlqpVW61Y11pft1/7qu1rWy1Wq1RtC2q1Wtdq3RWVfZNFFhHZISxhy07Inpn798ecxElI2OQwkLk/18XFnOc5c+Y+Gc3Nc55NVBVjjDEmItQBGGOMOTFYQjDGGANYQjDGGOOwhGCMMQawhGCMMcZhCcEYYwxwHBKCiCwTkTFBxwNE5DMRmSsib4pIlFP+vIgsEJFZIjLJ7biMMcbUF+nmxUXkB0Byg2IFLlbVShF5DLgUeAtIAcaqarGbMRljjGmcawlBRBKBa4B/B5er6qqgw0Kg1HmdCOw7ks9IS0vTTp06fY8ojTEmvHz11Vd5qpreWJ2bLYTJwO+BcY1VisgwoC/wJ6dIgVkiUgk8rKpzm3jfRGAiQIcOHVi6dOmxjtsYY5otEdnaVJ0rCUFErga2qeoSERnXoE6A+wAvcK2q+gBU9QKnvj3wETCgsWur6hRgCkBWVpatu2GMMceIWy2Eq4AyEXkd6AeMFJEtqroO+AWwS1VfCn6DiESqag2Bx0jVLsVljDGmCa4kBFWtaxWIyG+BL4HrReQB4GIgRUR+5pzyvqo+AXwqIpGAB/i1G3EZY4xpmqujjABU9bfOy0+dvy9s4rzRbsdijDGmaTYxzRhjDGAJwRhjjMMSgjHGGOA49CGciC5/dj65JZX0a5vMby/pS+vkmFCHZIwxIReWLYShXVpyesdUZq/PZdzkueyrsFGuxhgTli2Ee8f0AmD+xjyufm4Rc9bnctGAtiGOyhhjQissWwi1hnRpSUqcl+lr9oY6FGOMCbmwTgieCOGcnhnMXLcXn99WwTDGhLewTggA5/bOoKismhXbC0MdijHGhFTYJ4SB7VIA2Lh3f4gjMcaY0Ar7hNA6OYYIgZzC8lCHYowxIRX2CcHriaB1Ugw7iiwhGGPCW9gnBIDM1FhrIRhjwp4lBCAzJZYdlhCMMWHOEgKBFsLufRXU+PyhDsUYY0LGEgKQmRKHz6/sKakMdSjGGBMylhAItBDARhoZY8Kb6wlBRJaJyJig4wQReU1E5ojIuyKS5JRfJiJzRWSRiExwO65gmSlOQigqO54fa4wxJxRXE4KI/ABIblD8K+ADVR0BfA7cLCLxwN3AaGAUcL+IHLc1qdtZC8EYY9xLCCKSCFwD/LtB1SjgLef128BQYAgwXVUrVbUUWAT0ciu2hmK8HpJjveRaH4IxJoy52UKYDPweaDh0J1pVazcgyAdSgQwgN+ic2vIDiMhEEVkqIktzc3MbO+WotIiPoqDM9kUwxoQvVxKCiFwNbFPVJY1U+0Wk9nNTCSSCYuongNryA6jqFFXNUtWs9PT0YxZzapyXwtKqY3Y9Y4w52bjVQrgK6CMirwM/INAn0NOpWwRc6ry+AvgCWAyMERGviMQB/YC1LsXWqBbxURRYQjDGhDFXdkxT1XG1r0Xkt8CXwPUi8gDwCPCyiPwS2AjcqqqVIvIiMA8oBx5S1Ro3YmtKalwU3+TsO54faYwxJxTXt9BU1d86Lz91/s4DxjZy3lRgqtvxNCXQh1CFqiIioQrDGGNCxiamOVrER1FV46esyhfqUIwxJiQsIThS46MArB/BGBO2LCE4WsQFEkJhmSUEY0x4soTgsBaCMSbcWUJwtLCEYIwJc5YQHJYQjDHhzhKCIykmEk+EWB+CMSZsWUJwiAipcVEUlNp6RsaY8GQJIUiLeFvPyBgTviwhBAm0ECwhGGPCkyWEIMmxXorL7ZGRMSY8WUIIkhzrZV+FJQRjTHiyhBDEWgjGmHBmCSFIcqyXsiof1b6Gm7wZY0zzZwkhSHKcF8BaCcaYsGQJIUhyrCUEY0z4soQQJMkSgjEmjLm2Y5qIRAFvA4mAAFepao5T9xzQzTk1CchW1fEi8jzQG6gCFqvqvW7F1xhrIRhjwpmbW2jWABNUtUxEfgJcB/wRQFV/XnuSiEwGXnYOU4CxqlrsYlxNqk0I+ywhGGPCkGuPjFTVr6plzmF3YFXDc0SkI5ChqkucokTgoDvdi8hEEVkqIktzc3OPaczWQjDGhDNX+xBE5B4R2QBkATMaOeUu4KmgYwVmichnIjK8sWuq6hRVzVLVrPT09GMab11CKLOEYIwJP64mBFV9TFW7A08DzwTXiUgMcIqqLgw6/wJVPRu4oeH5x4PXE0FclMdaCMaYsORaQhCRRBER53AbkNDglLHAFw3eU9unUQiE5LeyzVY2xoQrNzuVewFPikglUA7cJiJ/Ah5Q1SpgJPBeg/d86iQFD/BrF2NrkiUEY0y4ci0hOB3FwxoU3xdU/8tG3jParXgOV5IlBGNMmLKJaQ1YC8EYE64sITSQHOu1eQjGmLBkCaGB5FgvRZYQjDFhyBJCAynOEthVNbYEtjEmvFhCaCDFWQK7qNz2VjbGhBdLCA2kxEUBNlvZGBN+LCE08F0LwRKCMSa8WEJoICU20EIoLLVHRsaY8GIJoQFrIRhjwpUlhAbqEkKZtRCMMeHFEkIDCdGRREYIRdapbIwJM5YQGhARUuJscpoxJvxYQmhEcqzXHhkZY8KOJYRGpMZF2SMjY0zYsYTQiJQ4L4WWEIwxYcYSQiNS4qIotkdGxpgwYwmhESmx1kIwxoQfN/dUjhKRD0RklojMFpHMoLr2IrLTqZslIn2c8stEZK6ILBKRCW7Fdiip8VGUV/uoqPaFKgRjjDnu3NxTuQaYoKplIvIT4Drgj05dCvCGqv6q9mQRiQfuBs514ponIu+paoWLMTYqOTYwOW1feTUxXs/x/nhjjAkJ11oIqupX1TLnsDuwKqg6BShs8JYhwHRVrVTVUmAR0KvhdUVkoogsFZGlubm5boReN1vZHhsZY8KJq30IInKPiGwAsoAZQVVxwBUiMl9EnhQRL5ABBP+GzwdSG15TVaeoapaqZqWnp7sSd6qzBLbNRTDGhBNXE4KqPqaq3YGngWeCyqep6kBgOFAC3AgUUz8BpFI/QRw3tY+MrIVgjAknbnYqJ4qIOIfbgISgukgIPFYi0BIAWAyMERGviMQB/YC1bsV3MKnxziY5tmuaMSaMuNmp3At4UkQqgXLgNhH5E/AAgcdFtwI+IBuYqKqVIvIiMM85/yFVrXExvialWAvBGBOGXEsIqroEGNag+D7n79ecPw3fMxWY6lZMhysuyoPXYyueGmPCi01Ma0RgxdMoe2RkjAkrlhCakBLrpbDUWgjGmPBhCaEJqXFRFFkLwRgTRiwhNCE5zmt9CMaYsGIJoQkpsZYQjDHhxRJCE1Lj7ZGRMSa8WEJoQnKsl4pqv614aowJG5YQmvDdekb22MgYEx4sITThuxVP7bGRMSY8WEJoQu3yFdZCMMaEC0sITUixJbCNMWHGEkITbJMcY0y4sYTQhJYJgRZC3v7KEEdijDHHhyWEJkRHemgRH8Wefcd9S2djjAkJSwgHkZEYzZ591kIwxoQHSwgH0Sophr0l1kIwxoQH1zbIEZEo4G0gERDgKlXNceoGAH8GYoFdwE9UtUpEngd6A1XAYlW91634DkerpGjW7t4XyhCMMea4cbOFUANMUNWRBHZBuy6oToGLVXU4sBW41ClPAcaq6shQJwMItBBySyrx+TXUoRhjjOtcSwiq6lfVMuewO7AqqG6VqtY+nC8ESp3XicAJ80/yjKQY/Ar5NtLIGBMGXO1DEJF7RGQDkAXMaKR+GNAXmOYUKTBLRD4TkeFNXHOiiCwVkaW5ubluhQ5Aq8RoAOtYNsaEBVcTgqo+pqrdgaeBZ2rLJeB+YBRwrar6nPMvUNWzgRuCz29wzSmqmqWqWenp6W6GT6ukGAAbemqMCQtudionAvtVVYFtQEJQ9S+AXar6UoP3RKpqDYHHSCGfIlyXEGykkTEmDDSZEETkHKBNg+IVwCkAqvqqiNypqk82cYlewJMiUgmUA7eJyJ+AB4CLgRQR+Zlz7vuq+gTwqYhEAh7g10d7U8dKWkIUIrDXHhkZY8LAwVoIHsDboOwyAo+ZfgS8ClwINJoQVHUJMKxB8X3O3xc28Z7Rh4j3uIr0RJCWEG2PjIwxYaHJhKCqXwQfi0g0cDfwCTCitti90E4MbZJj2FlsCcEY0/wdVqeyiLQDHiUwCiisZKbEklNYdugTjTHmJHfIhCAiacBk4E+NVDf7BJGZEktOUTmBvnFjjGm+DpoQRORzIBuYqqq7+e4RkYjICCDV3fBCLzM1lopqPwWltlGOMaZ5O2hCUNXzCMwy/pmIdCcwuWwH8BwwFPiP6xGGWGZKLAA5ReUhjsQYY9x1yHkIqrpLRG4AJqtq7TDRN9wN68SRmeokhMJyBrRLCXE0xhjjnsPqVFbVEuAOETnf5XhOONZCMMaEi8MdZXSvkxTub1DecOJas5Mc6yU+ysOOQksIxpjm7XBGGUUDHWsPG1T/+5hHdIIRETJTY62FYIxp9g6nhfAzvvvF33DsZbOfmAa1cxEsIRhjmrdDDTv9H6ADUCgi1wGtG5wSFoPz27eIY3tBmc1FMMY0a4dqIfiBGOfvGsIkATTUqWU8JZU1NhfBGNOsHWoewl+ALUBLVf03sPe4RHWC6ZQWB0B2fukhzjTGmJPX4fQhPAdc6bxWABF5QkQ+4bvO5matU8t4ALLzbE0jY0zzdTgT08pFZJ1zKE7ZXa5GdYJplxpHhFgLwRjTvB3uxLSnnZd/cDGWE1ZUZASZqbFk51sLwRjTfB3RnsoN90gIJ51axpOdZy0EY0zzdUQJ4UiISJSIfCAis0RktohkBtUliMhrIjJHRN4VkSSn/DIRmSsii0RkgluxHY1OLePJzi+1oafGmGbLtYRAYJjqBFUdCUwFrguq+xXwgaqOAD4HbhaReAI7so0GRgH3i0iMi/EdkU5p8ZRU1JBvQ0+NMc2UawlBVf2qWvvQvTuwKqh6FPCW8/ptAktpDwGmq2qlqpYCi4BebsV3pLpnJACwfk9JiCMxxhh3uNlCQETuEZENQBaBvRRqRatqtfM6n8BGOxlAbtA5teUNrzlRRJaKyNLc3NyG1a7p2ToRgPW7LSEYY5onVxOCqj6mqt2Bp4Fngqr8IlL72akEEkEx9RNAbXnDa05R1SxVzUpPT3cp8gNlJEaTHOtl3Z79x+0zjTHmeHKzUzlRRGoXv9sGJARVLwIudV5fAXwBLAbGiIhXROKAfsBat+I7UiJCz1aJ9sjIGNNsudlC6AXME5EZwCTgHhH5k4hEAY8AE0VkFnA68E9VzQNeBOYBHwMPqWqNi/EdsZ6tE1m/u8RGGhljmqVDzlQ+Wqq6BBjWoPg+5+88YGwj75lKYETSCalH60RKKmvYva+CNsmxoQ7HGGOOKVf7EJqbnq0CHcvrrGPZGNMMWUI4Aj1a2dBTY0zzZQnhCKTERdEqKZp1u22kkTGm+bGEcIR62EgjY0wzZQnhCPVslciGvSX4/DbSyBjTvFhCOEI9WidSUe1ne4EthW2MaV4sIRyhupFG9tjIGNPMWEI4Qt1bJSACq3fuC3UoxhhzTFlCOEJxUZFkdUzlo6932oxlY0yzYgnhKFxxWjs25ZayYntRqEMxxphjxhLCUbhwQBtivBG8vWxHqEMxxphjxhLCUUiK8TKyRwYz1x6//RiMMcZtlhCO0pAuLcgpKmdHoQ0/NcY0D5YQjtIZnVsCsCS7IMSRGGPMsWEJ4Sj1bJ1IUkwki7dYQjDGNA+WEI6SJ0IY1KkFs9fl8q3NSTDGNAOWEL6HK8/oQEFZFRf9dS5fbS0MdTjGGPO9uJIQRCRFRF4XkVkiMkdEOgfVPeeUzxKRZSLyjlP+vIgscMonuRHXsTa6TysW3n8uqXFRTJ6+IdThGGPM9+LWFppxwF2qulNExgF3A7cCqOrPa08SkcnAy85hCjBWVYtdiskVqfFR3DC8M5M+XcfXO4oY0C4l1CEZY8xRcaWFoKo7VXWnc1gIlDY8R0Q6AhnO3ssAicBJ+TD+miEdSYyOZOrcLaEOxRhjjpqrfQgikkmgdfBkI9V3AU8FHSswS0Q+E5HhB7nmRBFZKiJLc3NPjIlhiTFeJgxqz8erdrGruDzU4RhjzFFxLSGIyEXAg8CNQa2F2roY4BRVXVhbpqoXqOrZwA3AM01dV1WnqGqWqmalp6e7FP2Ru+7MTqgqk6dvtEXvjDEnJVf6EERkAHCxqt7UxCljgS8avCdSVWsIPGKqdiMuN7VvEcf1wzrz3LwtxEV5mDiiC62SYkIdljHGHDa3OpXHAMNFZJZzvA3YBTygqlXASOC9Bu/5VEQiAQ/wa5fictWvL+zN/soanp+3hdcXb+OTX46gRUIU8VEeRCTU4RljzEHJyfx4IysrS5cuXRrqMA6wbncJlz4zjwGZKXy7ax9XnJbJ7y7tF+qwjDEGEflKVbMaq7OJaS7o2TqR64d1ZnF2AeXVPl7+cqvNZjbGnPAsIbjk5pFduensLrx7yzCSY73c+/ZKFm3O55FP1lBR7Qt1eMYYcwB7ZHQcTF+zh5te/ooaf+Bn/eLPBjGyZ0aIozLGhCN7ZBRi5/ZuxT+uOZ0JWe2BQB+DMcacaCwhHCfn9m7Fn34wgNZJMaxtJCH4/Mptry7jvRU5IYjOGGPcG3ZqmtCrTWK9hOD3K7v2VbA6p5gPv97FjLV7Oa1DKu1bxNV7X0FpFQWlVXTLSKgrW7m9CICB7RtfP0lVbbirMeawWUI4znq2TmT+xjyqfX68ngienL6BydM30DophlZJ0ZRW+rhw8lzSEqIpKK1iSJcW3DumF3e+voJ1u0v4+zWnMapXK7YXlHHV1C+JjfIw775RxHg9VPv8/HP+Fnq2TmLPvgomfbqWqddm0To5hofeW02X9ATuH9sr1D8CY8wJyjqVj7N3l+dw5xsr6JaRQOe0eOZuyCUyIoL9lTX8v7G9OK1jKv9dnkNRWRUJ0ZFMW72Hap+fsiofGYnR7C2ppEV8FF6PUFhaTZXPzx8u78f4U9tx3T8Xs3hLAbFeD5EeoaSihlivhxq/n2qfkhgdyfIHzyPSY08KjQlXB+tUthbCcdarTSIAOwrLyM4rJUKED355Fuv3lDCqVwZeTwSDOrWoO//aocVM+MdCsjqm8vx1g3hn+Q7W7S5hU+5+/ndcJ6bO3cyzMzexYFM+i7cU8OBFfXhm5kaKy6v5508H8dLCbHq2SiQp1stj09axeue+Jh8xQeAR1p6SClJio4iN8rj94zDGnECshXCc+fzKE5+vY1SvVkR5IthXUc2wbmkHfc+u4nISY7wkRB+Yv5dmFzDx5a8oKK3iphFd+H8X9mbd7hL27KtgRI/vFv/LLalk0B++4L4xvbh5ZNcmYzvvidlszitlePc0Xr5hMABFZVUkx3rx+ZUavxLjDSSKb3fu49XFW+nRKpFrh3Y6yp+IMeZ4shbCCcQTIdxzwZE9x2+THNtkXVanFnz2qxHMWLOXy07NBAL9FD1bJ9Y7Lz0xmp6tElmwKa/JhPBNTjGb80rp0CKOhZvy2V9Zw8rtRVz3wmLuuaAn63aXsGJ7EZ/cORyfX/nh3xdQWuUjMkIY0T2dTmnxR3RfxpgTiz1MbgbSEqL50aD2REUe/Osc2rUlS7ILKK2sabR+7obA/hJ3X9CTGr/y7vIcbnt1GTV+5ekZG/nvihw255Xy+uLtzN+YT2mVj79MGIjXE8GkaWupqPbx8Iffcvmz85n06Vp8fkVV2bi35LgsCa6qbMrdb8uPG3OULCGEkYsGtKGi2s+n3+wGOOAX55wNefRtm8T5fVoR443gt++vprzax5MTTqGksob4qEhOaZ/CX2ds5N0VOSRERzKuf1tuOrsLH6/azbmPz+aF+Vuo8SnPztrE5c/O5/JnFzD6iTlMW73nmN6L368s21ZY7x6en7eFcx+fzYsLso/pZxkTLiwhhJHTO6bSoUUc7yzfwf7KGsZNnseEfyxkR2EZxeXVLNtayPDu6cR4PQzq1IIav3L7qO5cdmomE0d04YGLevPwpf0oKqvio693Mbx7GlGREdwxqjs3Du/MruJyHh3fnw9uP4tHxvdHNdD/EBflYfb6vcf0Xv46YyPjn13Af77aAcD2gjKe+Hw90ZER/OGjNSzfVnhMP8+YcGB9CGFERBh/WiZPTd/A1VO/ZO3ufcRFRTL2qbl0TovHr8rYfq0BuOqMDngihJ8P7wwE9nqodc8FPXnkk7Wc27sVABERwm/G9eHO0T2Idzq+rzyjA1ee0QGAn7+0lPkb84FAx3VZVQ2JMd7DjtvnV/4+exOXDGxL+xZxfLByJ3/5Yj0An3yzmwgRfvv+agDevXUY1zy/iGdmbuSyUzPZml/Gred0+z4/NmPChiWEMHPd0E58k1PMrHW53DumFxf2a8Odbyxn+fYinvjRwLohqWP7t2Fs/zaNXuPG4V3o2zaZIV1a1CuPb2QUFMCwbi35Ys0etheU8ebS7fxr4Va+uOts0hOj651XVFbFlDmbue7MThSUVrF4SwHdMxLYkl/KY9PWkZ1XykUD2/KrN1YwqFMqPVsn8uaSHczfmEf/zGQeGd+f7q0SufKMDjw9cyPzNuYBcPPZXYmIcG/GdrXPT2SE2Kxwc9KzhBBmUuOjeO66QXUzpQHevGkoufsrDzqaKVhEhHBW94MPlQ1WO6x21vpcXlu8neLyap74fD2PjO8PwB8++pbpa/YSHx3JqpxiFm0pYP3uEkqczm+vRxCBD7/exez1uXTLSOD5nw5i7a4SXvlyGzHeCCZfeSptUwLxXzW4A8/O2kRFtR+AbQVlRzUCqqLaR4RIo531FdU+dhSWEeXxcMXfF3DNkI7ccW538vZX8saS7fxsWCfioux/L3NycaUPQURSROR1EZklInNEpHNQXXsR2enUzRKRPk75ZSIyV0QWicgEN+Iy3/EGzVaO9EQcdjI4Gt0zEuiWkcDvP/yWvP2V9GmTxGuLt9H7gU959JO1vDA/m53F5Xyzs5hx/dvw1dZCRODjO4Zz13k9SE+I5pHL+1Ne7WNvSSV/HN+fpBgvp3dMpW/bJH41ukddMoDAMN1Hx/fn3jE9AVi358DFBL/eUcSPpyxkS14pAJU1PvY3GH1126vLGD5pBl9tLahXvmxbIRc8OYfRT8xhzFNzyC2p5Pl5WyitrOH2V5fz2LR11rFtTkquTEwTkbYAqrpTRMYBF6rqrU5df+B6Vf1V0PnxwDTgXAKtlnnAUFWtONjnnIwT08LV6p3FXP7sApJivEz/n7N5bfE25qzPZcGmfKIiI5jxP2ejCpkpsTzx+XrO7NaSM7t+1wpRVa5+bhHdMhL4v8PcjrSsqoY+D07jrvN6MKpXBr3bJLElr5St+aX8/qM1bMkrJatjKm/cNJT/ffcbFm3O59Ubh3DDS0v4zbjeXPv8YvyqREd6+PyuEbRLjaOgtIrz/zKH2KgIrjitHR+v2sWYvq2ZPGMjPVolsH7Pftokx1BZ42fefedYK8GccA42Mc31mcoiciZwmare6xwPB85R1f8LOudcYISqPuQc/x34u6quONi1LSGcXL7cnI8Ag7u0BAKPXe56cwWntE9h4ojGJ8t9XyMmzaS82kduSSXXDu3IJ9/sJrekEoCfDOnAK19u49Hx/Zk0bR0FpVWM6pXBjLV7SU+MJrekkqd+fAr3vf01o3pl8MxVp3HLv5cxfc1e3rttGL3bJAGBZDX2qblszi3lzvO6M7hzS6742wIevqwf1wzpeMgYSytriIvyHHEfRLXPz/o9JfRtm3zkPxgTtkI2U1lEMoG7gduCiuOAK0TkAmAJcA+QAeQGnZMPpDZxzYnARIAOHTq4ELVxyxAnEdSK8Xp49urTXf3Mnq0T+fzbwByIfy3cSoTA4z8cSJvkGIZ2bcnS7MK6ZAAwY21geGxuSSXJsV7G9W/D9oIy/vzZem759zI++WY394/tVZcMIDB66183nEGNT+seXXVOi2f6mj2HTAhFZVWc9aeZ3D+2F+f3bUVRWTU9WiUecJ6qsr2gnA4tv1sWfcqczTw2bR1v/WJovfWvjDlars1DEJGLgAeBG1V1Z225qk5T1YHAcKAEuBEopn4CSKV+gqijqlNUNUtVs9LT0xs7xZg6PZ1frned14POafHcPqo7V5zejjO7pSEi/CirPQWlVYjA4M6BX6o3nd0FgBE90on0RDBxRFfG9mvNJ9/s5oxOLbhxeJcDPicjMaZeP8bInuks3JRPedWB+2d//u0eXl20DVVlgbNEyCtfbuWWV5Zx1dQv2VdRzS9fX06283hrU+5+Xlm0jRGPzeRfC7OBwMS8VxdtA+CPH6+x2dnmmHClhSAiA4CLVfWmRuoiVbVGVf0iku8ULwZ+IyKPAl6gH7DWjdhMeBnbvzVb8ku5cXgXbjun2wHDTy8/NZNHP1lLn7ZJ3Dm6B49+upbbzulG79ZJDGgXeBQTFRnBX688lXeW5TCyVzqewxjCOqpXBv+cn81LC7MZ2qUlfdoGOtLHn9aOhz/8lm0FZSzJLqhbUTZ406RnZmzkvRU72buvko25+9lfUYPXI3gihIc//JZ+mcmUVNSQU1TOOT3Tmbkul6lzN7v22M2ED7c6le8FfgrUTk/dBuwCHgCuAG4FfEA2MFFVK0XkRuDnQDnwO1WdeajPsT4Ecyy8tyKHtimxx/SxS2WNj1N+9znl1T7iojzcP7YXD763mp8N68Q/52fTq3Vg57yoyAhOaZfCyh1FJERHkl9aRVRkBFU1gSGzkRFC25RYdhSW8eqNQ7jnPyup8SmxXg/F5dXMv38Ud725go9X7eapH59C37bJLNqSz9WDD913YcJTSDuV3WQJwZzI3l+5k417Spg8YyNej1DtUyIjhBq/8uHtZ/E/b65k3Z4SHryoD62TY0hPjOaet1aSnV/GJQPbsqu4nDH92nDFaZlsLyinf7tkvskpZvzfFhAdGcELPx3EoE4tqPb5ueyZ+VRU+8hIjGHh5nwW/6tTur8AABIaSURBVPpcMpJiQv0jMCcgW/7amBC4ZGBbABZuzmdJdiEdW8axNb+MlDgvfdok8dAlfbj91eWc2zuDji0DE+eGdm1Jdn4ZY/u1rjdTPCUuCoB+mcm8c/OZJMd66/bd9noi+Nmwztz91ko25ZbWfWaECIO7tCAj8egSQ43Pz/i/LWD8qZn8dFjnQ7/BnPRscTtjXHbn6B4MaJfMkxNOAQKd1xERwpld0/jqgfPqkgHA5ae245T2KQzv0fSAiX6ZyXXJoNZFA9qQGhfYRCkhOpJnZ27i9teWc+NLS6mq8ePzKxuCJuipKiUV1ZRUVDf5OXM25PL1jmKmzNmMz//dk4SK6u86yvfuq+CVL7fWqzcnL2shGOOyYd3SeP+2swC47ZxuDD/Ish9ndG7Bu7cOO+LPiPF6+PMPB1LtU95aup3pa/cS441g5Y5iHpu2lkhPBH+btYmLBrThsR8M5KH3v+HNpTvwRAjDu6fx8KX9Dkgyby7ZgQjsLK5gzvpczumVwebc/Vzy9HwuOaUtv7+0H3e8vpwvNxfQMj6qybWvzMnD+hCMaWamztnMHz5ew+2julFUVs3LX24lMkLolpHA2t0l/O+43jzx+XpO65BK/3bJvPLlVmK9Hv51wxn0ah2YX7G3pIIzH5nBT4Z05MOvd6IamEeyZ18Fy7cX4fMrXdLi2ZxXSnRkBL3aJPHuLWfaAn8nAetDMCaMXDQwsB7UdWd2IiE6kqVbC9lRWMbLNwzmqqlf8vTMjZRV+fjpmZ0Y3acVl5+ayTXPL+LqqYvol5lMtc9P25RYFLjuzE6M7t2K1xZvY/6mPIrKqvntxX2o8SvT1+zl9I6pDGiXzAPvrWbxloK6Wejm5GQtBGOauf2VNRSXV5OZEsvjn63jr86opxUPnl+3ZPnm3P38eMqX1PiV4vJqfH7lJ0M68PvL+tddZ19FNV9lF3J2j/R68znKq3wMeWQ6Z3VP45mrTqv32buLK0hPjD6suRvm+DhYC8E6lY1p5hKiI8l0ZlGPcTZAyurYot7+FV3SE5h590gW3D+KR8f3p2/bJO44t3u96yTFeDmnV8YBk/tiozz88PR2TPtmN3tLvluPcmdROSMem1m38uu63SXc9caKep3SjSmv8pG3v/Ko79ccPUsIxoSRPm2SuHhgW64deuDEtfjoSGK8Hn6Y1Z6P7hh+RMNVrx7SkRq/cv2LS5i1LjAf9Z1lO6iq8fPBysDKNS8u2MI7y3Pq1otS1UZHJ93+2nIufXo+fhu5dNxZQjAmjIgIf73y1GM+IqhzWjyPju9PcXk1t7+2nH0V1fznq8AopRXbi8gpKq9bZPDd5Tms3lnM+X+Zwym/+4xf/3dV3fDXr7YW8sWaPeQUlbNyRxHbC8r46Otd9VoeAGt27aOsquaAOMz3Y30Ixphj5usdRVzy9HyGdmnJws353DyyK3+btYkL+7fm41W76dAijp1F5URECCmxXs7qlsZ7K3fSsWUcD13clz9PW0dOUTn7yqvJ6pTKkuxCfH5lePc0Xr5hMAArtxdx6TPz6ZaRwOM/HEiX9HgKS6vrrQRrmmZ9CMaY42JAuxTO6pbGws35jOiRzi/P7c7A9il8vGo3Xo8w6QcD8KtyVrc0PvnlcJ6YcAr//vlgSitruO6FxazfU8IfL+/PGZ1b8OXmAtqnxnLT2V2YuyGPBZsCe2RPmraWlDgvhaVVXPrMfAb87jNGPT6LPfsOup+WOQzWQjDGHFPbC8qYuyGPCYPa44kQ9lfW8O7yHGK9Hq44vR25JZWkJUTVm7Owr6Kafy3IZlSvVvRpm8TLC7N58P3VvPrzIZzaIYVz/jyL6MgILhrQlqdnbuTBi/pwxWnt+HDVTr7JKea1xduZcs3pnN+3dehu/CRhi9sZY04qPr+yo7CsblmPr7YWcP2LSykur+bC/q15csKpREUGHnCUV/no+9Cn3DaqO3ed1+OwP8PvV/42exNJsd7D2tmuubCJacaYk4onQuqt8XR6x8CSHsu2FnL5qZn1hr7GRnnolpHA6pziI/qMu99ayTvLc0iMieTHg9rj9QQSTEFpFdGREfWG5dball/G4uwCfnB6OyAwUqo5zc62PgRjzEmhc1o8V5ze7oB5EBBY8G/VIRJCVY2/bj/tvfsqeGd5Dv2dzYaWZhcCgV/wV/xtATe9/FWj15g6dzN3v7WSOetzufTpefT430/406fNZy8vSwjGmJNev7bJ7C2pZG8THcsLN+Vz7hOzGPSHLxj71Fymrd4NwG/G9SbKE8H0NYEhscu3F7Elr5R5G/OYvzGP0soa/vL5erLzAsuKr9xRBMDEl5eyKqeYlvHRLNlScBzu8PiwR0bGmJNev8zAdqdDHplOp7R4LhnYlqsGd+Dr7cW0bxHH9S8uoXVyDHeM6sbkGRuZNG0dSTGRDOrUgiFdWzLt293cMbo7H6zcSVRkBC3ionjgvW9olxrHnPW5vLggm6nXZrFm1z7iozyUOmtB7a+sYe6GRrd/Pym5tadyCvB3oDWBVsh1qrrFqRsA/BmIJbCt5k9UtUpEngd6A1XAYlW9143YjDHNz+kdU/nNhb0pKKvim5xinvxiA09N34AqREhgFvarNw6mTXIsczfmsXxbEef3aYUnQrh6cAdu+fcyzn18NuVVPs7pmc5PhnTkztdXsDk3l1tGduWdZTnc+uoyqn3K7y7pw7aCMm45pyv/nJfNnn2VVNb4iI70hPrH8L251UKIA+5S1Z0iMg64m8A+ygAKXOzso/wYcCnwFpACjFXVI+sZMsaEPU+EcOOILnXHH6/axdwNeQzqlMqLC7K5ZWRX2iQH1nO6dmhHlm8rYmjXwMqsF/Rtzds3n8mzMzeyp6SS64d1ZnCXlsz4n5Gs3lXM0C4tSY718sgngb6CET3SaJcamATXLjVwzZ1FFXROi+dk50pCUNWdQYeFQGlQ3aom6hKBfYe6tohMBCYCdOjQ4XvHaoxpfi7s34YLneU5xp/Wrl7dRQPaUlhaXTdSCOCU9ilMubb+SMzkOC9ndg1sZvSjrPY88fl6EmO+WygQqNtUaHtB2VElhIWb8klPjKZbRkJdmaqyJa+U9MRoEmO8R3zN78PVTmURySTQOniykbphQF9gmlOkwCwR+UxEhjd1TVWdoqpZqpqVnt70NoPGGNMYryeC68/qfES/bFPjo/jl6O5cO7RTvWGmtS2EHYXldWXPzd3M8m2FrNtdwlNfbKDG52/0mvsra7j2hUWMfWoOLzkrwpZW1nD+X+Yw6vHZ3Prq8gPes3b3PlZsLzrsuI+Ua53KInIRcDFwo6rmB5ULcB/gBa5VVR+Aql7g1LcHPgIGuBWbMcYcqVtGdjugrFVSDF6PsKOwDICconJ+/9Eazuzaklivh+lr91Je7eP+sb0OeO/iLflU+5QerRL43Qer6ZeZzKbc/WzYu5+zuqUxZ30u6/eU0KNVIiUV1STGePnlayvYnLeff/70DM46yFasR8uVFoLTcXyxqt4UnAwcvwB2qerDtcnAeU9tcioEmt752xhjThCeCKFtSiwLNuUz6dO1vLciB4CFm/OZvT6X1Dgvf5+9iTteW05xWf1fa/M25BMdGcGrNw6hTXIsv3pjBS8tyKZLejyTrzyV6MjAPthvLd3OwN99xt9nb2LdnhIE4RevfNXkENvvw60WwhhguIjMco63ERhR9ACBVkOKiPzMqXtfVZ8APnWSggf4tUtxGWPMMdUuNZb5G/NZsb2IyAghIzGavSWV1Kjy/E8HMWPNXv42exOZqbHcN6YXFdU+NuzZz7yNuWR1SiUtIZrJV57CdS8sYVtBGfeP7UWL+CiuGtyBf87P5r/LA0lmkjMB7qXrz2B7QRkZSYe/X8XhcqtTeRIwqYnqC5t4z2g3YjHGGDf1aZPEut37Ob1jCtNW7+GqwR2YtS6X0soaTm2fwmkdUlm6tYCZa/dyxWmZ3PzKMjbs3Q/AZadmAoGlOd64aQgvzs9mQlZ7AB4Y14fTO6ayaHMB7VJjeeSTtXROi2do15Z1I6SONVvczhhjvgefX6mq8eNT5cnP1zPRGf7qU60b6vqP2Zt45JO1dGgRR2llDbeP6sbmvFJuG9XtsHamK6/ycfZjM/lRVnvuvqDn94rXVjs1xpgQWr+nhPP/MgeAp686lYsGtD3ia5RV1RAd6cHTyFpOR8JWOzXGmBDqnpFAp5ZxpMZHMe4oty+Ni3L/17UlBGOMcZmI8NrEIcR6PSf0ctmWEIwx5jio7U84kdny18YYYwBLCMYYYxyWEIwxxgCWEIwxxjgsIRhjjAEsIRhjjHFYQjDGGAOc5EtXiEgusPUo354G5B3DcE4Gds/hwe45PBztPXdU1UZ3FzupE8L3ISJLm1rPo7myew4Pds/hwY17tkdGxhhjAEsIxhhjHOGcEKaEOoAQsHsOD3bP4eGY33PY9iEYY4ypL5xbCMYYY4JYQjDGGAOEaUIQkYdFZLaIzBeRvqGOxy0iskpEZjl/rhKRniIy3bnvx0Id37EiIuki8gcRedg5bvQ+m9P33sg9XyMi3zrf9WdB5zWne04Rkdede5wjIp2b+3fdxD279l2H3QY5IjIcaKWqZ4tIP+Ax4MIQh+WWPao6uvZARD4BblDVbBF5S0QGq+qiEMZ3rDwObATinOMnaXCfQBTN63tveM8pwP9T1fdqT2iG/63HAXep6k4RGQfcDXSheX/Xjd3zWlz6rsOxhXA+8BqAqn4DtAhtOK7y174QkUggRlWznaK3gaGhCOpYU9VrgTlw0PtsVt978D07UoDCBqc1t3veqao7ncNCoJJm/l03cs+luPhdh2NCyAByg45rRKTZ/RxEJB7o6jQz3wTaAPlBp+QDqSEJzl3pNH6fzf17jwQmichcEZnolDXLexaRTAL/Un6cMPmug+75SVz8rsPukRFQTP1fhH5V9Td18slKVUuBrgAich7wBIF/WdRKpf5/QM1FEY3fZyzN+HtX1YeAh0QkDnhPRObTDP9bF5GLgIuBG4EywuC7Dr5nVc0HXPuuT+qseZTmAj8AEJE+wI7QhuMOEfEEHeYCCkQ7/9IAGA9MP+6BuUxVy2n8Ppv19+48KgMoB0oIfN/N6p5FZABwsarepKr54fBdN7xnp8y17zocWwgfAReKyFwCP8ybQhyPW7qJyAtAlfPnZqAl8B8RqQTeV9U1oQzQRXfR4D5FZB3N+3t/RETOIPD/9H9V9VsRWUvzuucxwHARmeUcb6P5f9eN3fMet75rm6lsjDEGCM9HRsYYYxphCcEYYwxgCcEYY4zDEoIxxhjAEoIxjRKR10IdgzHHmyUEE9ZE5NOg1yNF5H7n8IBNyJ1F1Lo1+DPjuAVrjMvCcR6CMcE8ItLOeX1AEmggDjirkbImicgTwLOqurFBeRTwDNAdiAFuU9WlItIaeA5IBjYRmJF7BRCnqi8cxv0Yc9QsIZhwl0xgjRiAdsBS57WIyG3ATFVd7ZQlAT9p8P4UmuCsOrmvYTJwRAGPq+paZ6niScA44A/AH1V1gbOc83hVfV1E3hORt1W1+Ghu0pjDYY+MTLgrUNU7VfVO4OkGdWsJrI0EgKr2dZYTfxF4RVVHq2qvg1z7x8C/RCTZWWQwWkT6isjrqrpfVdc659WuYgnQU1UXOK+DV6R9H7jkqO/SmMNgLQQT7pJF5D/O65YEljYBUFX9AuoWB/xN0HtaBIrlp0Flj6rqp9TXXlU3O9d4jMAyC1kElhHBKU8hsGrn/zlFwf9IC16RdhlwDfDykd6gMYfLEoIJa6p6yD0hVPVz4POjuXzQNT5wOqzfV9W9ACIyBLgFuF9VtzqnStD7g1ekLQXijyIGYw6bJQQT9kRkmqpeEFwWvNOcc04r4N+NvL2HqnZo4tI+EYlS1SoRGQt8AYwUkX8QWKL5bmCCqvqC3pMjIqep6jICnclfOOVtgZ0Y4yJLCMaA51AnqOoeYHTDchH5opHTa80nkABWEvjlPwYYDEwGPgROA6aLCECVqp4P3Ae8ICJ+YAkwzbnWeXz3OMsYV9hqpybsOXMJGttM5E5nO8KDvfeLhq2JoLpYYIqqXvM940sF/qGqP/o+1zHmUCwhGPM9iEgrp/XQVP1gYE/Qvr9H8xkjgXWquutor2HM4bCEYIwxBrB5CMYYYxyWEIwxxgCWEIwxxjgsIRhjjAEsIRhjjHFYQjDGGAPA/wdIz43ogCqzfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "\n",
    "\n",
    "# 모델 등 생성\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "# model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "# 학습 시작\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "# 나중에 사용할 수 있도록 필요한 데이터 저장\n",
    "word_vecs = model.word_vecs\n",
    "\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_params.pkl'  # or 'skipgram_params.pkl'\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CBOW 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " we: 0.6103515625\n",
      " someone: 0.59130859375\n",
      " i: 0.55419921875\n",
      " something: 0.48974609375\n",
      " anyone: 0.47314453125\n",
      "\n",
      "[query] year\n",
      " month: 0.71875\n",
      " week: 0.65234375\n",
      " spring: 0.62744140625\n",
      " summer: 0.6259765625\n",
      " decade: 0.603515625\n",
      "\n",
      "[query] car\n",
      " luxury: 0.497314453125\n",
      " arabia: 0.47802734375\n",
      " auto: 0.47119140625\n",
      " disk-drive: 0.450927734375\n",
      " travel: 0.4091796875\n",
      "\n",
      "[query] toyota\n",
      " ford: 0.55078125\n",
      " instrumentation: 0.509765625\n",
      " mazda: 0.49365234375\n",
      " bethlehem: 0.47509765625\n",
      " nissan: 0.474853515625\n"
     ]
    }
   ],
   "source": [
    "# pkl_file = 'cbow_params.pkl'\n",
    "pkl_file = 'cbow_params_epoch10.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    word_vecs = params['word_vecs']\n",
    "    word_to_id = params['word_to_id']\n",
    "    id_to_word = params['id_to_word']\n",
    "\n",
    "# 가장 비슷한(most similar) 단어 뽑기\n",
    "# querys = ['you', 'year', 'car']\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    if x.ndim == 2:\n",
    "        s = np.sqrt((x * x).sum(1))\n",
    "        x /= s.reshape((s.shape[0], 1))\n",
    "    elif x.ndim == 1:\n",
    "        s = np.sqrt((x * x).sum())\n",
    "        x /= s\n",
    "    return x\n",
    "\n",
    "def analogy(a, b, c, word_to_id, id_to_word, word_matrix, top=5, answer=None):\n",
    "    for word in (a, b, c):\n",
    "        if word not in word_to_id:\n",
    "            print('%s(을)를 찾을 수 없습니다.' % word)\n",
    "            return\n",
    "\n",
    "    print('\\n[analogy] ' + a + ':' + b + ' = ' + c + ':?')\n",
    "    a_vec, b_vec, c_vec = word_matrix[word_to_id[a]], word_matrix[word_to_id[b]], word_matrix[word_to_id[c]]\n",
    "    query_vec = b_vec - a_vec + c_vec\n",
    "    query_vec = normalize(query_vec)\n",
    "\n",
    "    similarity = np.dot(word_matrix, query_vec)\n",
    "\n",
    "    if answer is not None:\n",
    "        print(\"==>\" + answer + \":\" + str(np.dot(word_matrix[word_to_id[answer]], query_vec)))\n",
    "\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if np.isnan(similarity[i]):\n",
    "            continue\n",
    "        if id_to_word[i] in (a, b, c):\n",
    "            continue\n",
    "        print(' {0}: {1}'.format(id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[analogy] king:man = queen:?\n",
      " woman: 5.16015625\n",
      " veto: 4.9296875\n",
      " ounce: 4.69140625\n",
      " earthquake: 4.6328125\n",
      " successor: 4.609375\n",
      "\n",
      "[analogy] take:took = go:?\n",
      " went: 4.55078125\n",
      " points: 4.25\n",
      " began: 4.09375\n",
      " comes: 3.98046875\n",
      " oct.: 3.90625\n",
      "\n",
      "[analogy] car:cars = child:?\n",
      " children: 5.21875\n",
      " average: 4.7265625\n",
      " yield: 4.20703125\n",
      " cattle: 4.1875\n",
      " priced: 4.1796875\n",
      "\n",
      "[analogy] good:better = bad:?\n",
      " more: 6.6484375\n",
      " less: 6.0625\n",
      " rather: 5.21875\n",
      " slower: 4.734375\n",
      " greater: 4.671875\n"
     ]
    }
   ],
   "source": [
    "# 유추(analogy) 작업\n",
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkipGram 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * rn(V, H).astype('f')\n",
    "        W_out = 0.01 * rn(V, H).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layer = Embedding(W_in)\n",
    "        self.loss_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "            self.loss_layers.append(layer)\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer] + self.loss_layers\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = self.in_layer.forward(target)\n",
    "\n",
    "        loss = 0\n",
    "        for i, layer in enumerate(self.loss_layers):\n",
    "            loss += layer.forward(h, contexts[:, i])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dh = 0\n",
    "        for i, layer in enumerate(self.loss_layers):\n",
    "            dh += layer.backward(dout)\n",
    "        self.in_layer.backward(dh)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkipGram 모델 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ptb\n",
    "import pickle\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "window_size = 5\n",
    "# window_size = 2\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 10  # 10회 이상  , 전체 데이터로 epoch 8회 학습  ==> '7시간 소요'\n",
    "\n",
    "# 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1326\n",
      "1326\n",
      "1326\n"
     ]
    }
   ],
   "source": [
    "# PTB 데이터 중 일부만 사용시\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "corpus_size = 5000\n",
    "corpus = corpus[:corpus_size]\n",
    "\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "temp1,temp2 = {},{}\n",
    "for k in range(vocab_size):\n",
    "    word1= list(word_to_id.keys())[k]    \n",
    "    id1 = list(word_to_id.values())[k] \n",
    "    temp1[word1] = id1\n",
    "    \n",
    "    word2= list(id_to_word.keys())[k]    \n",
    "    id2 = list(id_to_word.values())[k] \n",
    "    temp2[word2] = id2\n",
    "    \n",
    "word_to_id = temp1\n",
    "id_to_word =temp2\n",
    "\n",
    "print(len(corpus))\n",
    "print(vocab_size)\n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 49 | 시간 0[s] | 손실 41.59\n",
      "| 에폭 1 |  반복 21 / 49 | 시간 3[s] | 손실 41.57\n",
      "| 에폭 1 |  반복 41 / 49 | 시간 6[s] | 손실 41.31\n",
      "| 에폭 2 |  반복 1 / 49 | 시간 7[s] | 손실 40.72\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "\n",
    "# 모델 등 생성\n",
    "model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "# 학습 시작\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "# 나중에 사용할 수 있도록 필요한 데이터 저장\n",
    "word_vecs = model.word_vecs\n",
    "\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'skipgram_params.pkl'\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " yourself: 0.693359375\n",
      " anybody: 0.666015625\n",
      " i: 0.66015625\n",
      " somebody: 0.6328125\n",
      " your: 0.63134765625\n",
      "\n",
      "[query] year\n",
      " month: 0.60986328125\n",
      " earlier: 0.5537109375\n",
      " week: 0.5419921875\n",
      " quarter: 0.541015625\n",
      " fiscal: 0.53759765625\n",
      "\n",
      "[query] car\n",
      " cars: 0.65380859375\n",
      " luxury: 0.58203125\n",
      " mazda: 0.54638671875\n",
      " beretta: 0.52099609375\n",
      " truck: 0.51513671875\n",
      "\n",
      "[query] toyota\n",
      " lexus: 0.7197265625\n",
      " honda: 0.68359375\n",
      " motor: 0.68115234375\n",
      " infiniti: 0.6787109375\n",
      " mazda: 0.6318359375\n"
     ]
    }
   ],
   "source": [
    "# pkl_file = 'skipgram_params.pkl'\n",
    "pkl_file = 'skipgram_params_epoch08.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    word_vecs = params['word_vecs']\n",
    "    word_to_id = params['word_to_id']\n",
    "    id_to_word = params['id_to_word']\n",
    "\n",
    "# 가장 비슷한(most similar) 단어 뽑기\n",
    "# querys = ['you', 'year']\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[analogy] king:man = queen:?\n",
      " teacher: 1.90234375\n",
      " incest: 1.8935546875\n",
      " hero: 1.736328125\n",
      " mystery: 1.736328125\n",
      " duck: 1.62109375\n",
      "\n",
      "[analogy] take:took = go:?\n",
      " ran: 1.66796875\n",
      " went: 1.5166015625\n",
      " walked: 1.4921875\n",
      " amsterdam: 1.4775390625\n",
      " pricings: 1.41015625\n",
      "\n",
      "[analogy] car:cars = child:?\n",
      " rape: 2.439453125\n",
      " adults: 2.2578125\n",
      " incest: 1.935546875\n",
      " districts: 1.818359375\n",
      " children: 1.806640625\n",
      "\n",
      "[analogy] good:better = bad:?\n",
      " ever: 1.5927734375\n",
      " vary: 1.4326171875\n",
      " comparable: 1.4189453125\n",
      " ca: 1.3212890625\n",
      " abbie: 1.306640625\n"
     ]
    }
   ],
   "source": [
    "# 유추(analogy) 작업\n",
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
