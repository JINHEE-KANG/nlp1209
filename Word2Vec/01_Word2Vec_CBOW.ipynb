{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론(예측) 기반 기법과 신경망\n",
    "\n",
    "## word2vec : 워드투벡터\n",
    "2013년 구글의 토마스미콜로프(Tomas Mikolov)의 팀이 개발<br>\n",
    "<b>word2vec</b> 알고리즘은 <b>신경망 모델</b>을 사용 하여 큰 텍스트 코퍼스에서 단어 연관성을 학습. 학습이 끝나면 이러한 모델은 동의어 단어를 감지하거나 부분 문장에 대한 추가 단어를 제안 할 수 있다. word2vec는 <b>벡터</b> 라고하는 특정 숫자 목록을 사용하여 각각의 고유 한 단어를 나타낸다 . 벡터는 간단한 수학적 함수 ( 벡터 간의 코사인 유사성 ) 가 해당 벡터가 나타내는 단어 간의 의미 유사성 수준을 나타내 도록 신중하게 선택 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] 신경망에서의 단어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\n",
      " [[1 0 0 0 0 0 0]]\n",
      "W:\n",
      " [[ 1.73494917 -0.6792979  -0.47629215]\n",
      " [-0.13494612 -1.26636489 -0.49621653]\n",
      " [-1.04138852  0.63699059  1.70535055]\n",
      " [ 0.38796549  0.55831096 -1.11404561]\n",
      " [-1.69460903 -1.58329166  0.18609043]\n",
      " [ 1.27276259 -0.2471758  -1.22873069]\n",
      " [-0.27275466 -0.01644975  1.11851969]]\n",
      "h:\n",
      " [[ 1.73494917 -0.6792979  -0.47629215]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
    "# 여기서 'you'만  one-hot 인코딩으로 표현\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0]])\n",
    "print('c:\\n',c)\n",
    "W = np.random.randn(7,3)\n",
    "print('W:\\n',W)\n",
    "\n",
    "h = np.matmul(c,W)  # (1,7) * (7,3) = (1,3)\n",
    "print('h:\\n',h)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self,W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x,W)\n",
    "        self.x = x\n",
    "        return out\n",
    "        \n",
    "    def backward(self,dout):\n",
    "        W, =self.params\n",
    "        dx = np.dot(dout,W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0] = dw\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\n",
      " [[1 0 0 0 0 0 0]]\n",
      "W:\n",
      " [[ 0.89181419  0.37260064 -0.08562695]\n",
      " [ 1.00812869 -0.71500708  0.01336081]\n",
      " [-0.57827798 -0.89016457  0.39237558]\n",
      " [ 1.31115867 -0.70202898  0.77247627]\n",
      " [-0.44671184  0.09205213  1.1595999 ]\n",
      " [ 0.12735275  0.48702139  0.32094946]\n",
      " [-0.56293981 -0.13989846 -1.07983125]]\n",
      "h:\n",
      " [[ 0.89181419  0.37260064 -0.08562695]]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
    "# 여기서 'you'만  one-hot 인코딩으로 표현\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0]])\n",
    "print('c:\\n',c)\n",
    "W = np.random.randn(7,3)\n",
    "print('W:\\n',W)\n",
    "\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)  # (1,7) * (7,3) = (1,3)\n",
    "print('h:\\n',h) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] 단순한 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW (Continuous Bag of Words) 모델\n",
    "\n",
    "#### Word2Vec에는 CBOW(Continuous Bag of Words)와 Skip-Gram 두 가지 방식이 있다\n",
    "- $ CBOW $ 는 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법 <br>\n",
    "  타깃(target)은 중앙 단어 그 주변 단어들이 맥락(contexts)이다\n",
    "- $ Skip-Gram $ 은 중간에 있는 단어로 주변 단어들을 예측하는 방법\n",
    "\n",
    "#### BOW(Bag of Words) : 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
    "\n",
    "BOW를 만드는 과정<br>\n",
    "(1) 우선, 각 단어의 고유한 인덱스(Index)를 부여한다.<br>\n",
    "(2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터(Vector)를 만든다.<br>\n",
    "\n",
    "\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"<br>\n",
    "('정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9) <br>\n",
    "BOW: [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]  ==> '가' 와 '물가상승률' 은 2회 발생\n",
    "\n",
    "https://wikidocs.net/22650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37464554 -0.23708098  0.27508264 -0.79749342  0.18501914 -0.09826488\n",
      "   0.24768791]] (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (CBOW 전체구조의 Preview)\n",
    "# 샘플 맥락 데이터 : 2개의 주변 단어를 맥락으로 중간 단어('say')를 예측\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "# 2개의 주변 단어를 one-hot 벡터 생성\n",
    "c0 = np.array([[1,0,0,0,0,0,0]])  # 'you'   , (1,7)\n",
    "c1 = np.array([[0,0,1,0,0,0,0]])  # 'goodbye' (1,7)\n",
    "\n",
    "\n",
    "# 가중치 초기화\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "# 계층 생성\n",
    "in_layer0 = MatMul(W_in)   \n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 순전파\n",
    "h0 = in_layer0.forward(c0)  # (1,7) * (7,3)  = (1,3)\n",
    "h1 = in_layer0.forward(c1)  # (1,7) * (7,3)  = (1,3)\n",
    "h = 0.5 * (h0 + h1)         # 입력층이 여러 개이면 전체를 평균\n",
    "s = out_layer.forward(h)    # (1,3) * (3,7)  = (1,7) ,최종 출력\n",
    "print(s,s.shape)            # (1, 7), 7개 단어의 스코어\n",
    "np.argmax(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 맥락과 타깃을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you\n",
      "say\n",
      "goodbye\n",
      "and\n",
      "i\n",
      "say\n",
      "hello\n",
      ".\n",
      "[0 1 2 3 4 1 5 6]\n",
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "[0 1 2 3 4 1 5 6]\n",
      "{'i': 0, 'like': 1, 'apple': 2, 'and': 3, 'you': 4, 'banana': 5, '.': 6}\n",
      "[0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n",
      "0.7071067691154799\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "[0 1 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 1]\n",
      "0.49999999292893216\n",
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "from mynlp import preprocess,create_co_matrix,cos_similarity,most_similar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.' \n",
    "corpus, word_to_id,id_to_word = preprocess(text)\n",
    "print(corpus)     # 8 개\n",
    "print(id_to_word) # 7 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [1 2 3 4 1 5]\n",
      "contexts: [[0, 2], [1, 3], [2, 4], [3, 1], [4, 5], [1, 6]]\n"
     ]
    }
   ],
   "source": [
    "# target : (6,)\n",
    "target = corpus[1:-1]  # 타깃(중간단어) : [1 2 3 4 1 5], 첫번째와 마지막 단어 제외\n",
    "print('target:',target)\n",
    "\n",
    "# contexts : (2,6)\n",
    "# print('corpus:',corpus)\n",
    "\n",
    "contexts = []\n",
    "for idx in(range(1,len(corpus) - 1)): # 1 to 6 ,6회, 중간단어마다 앞뒤 주변단어 조합 6가지 \n",
    "    cs = []\n",
    "    for t in range(-1,2) : # 3회 , (-2, 0 ,1)\n",
    "        if t == 0: # 2번째는 skip\n",
    "            continue\n",
    "        cs.append(corpus[idx + t]) # corpus[1-1,1+1],[2-1,2+1],...\n",
    "    contexts.append(cs)\n",
    "print('contexts:',contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts와 target을 구하는 함수\n",
    "def create_contexts_target(corpus,window_size=1):\n",
    "    target = corpus[window_size:-window_size]  \n",
    "\n",
    "    contexts = []\n",
    "    for idx in(range(window_size,len(corpus) -window_size)): \n",
    "        cs = []\n",
    "        for t in range(-window_size,window_size+1) : \n",
    "            if t == 0: \n",
    "                continue\n",
    "            cs.append(corpus[idx + t]) \n",
    "        contexts.append(cs)\n",
    "    return np.array(contexts),np.array(target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n"
     ]
    }
   ],
   "source": [
    "contexts,target = create_contexts_target(corpus,window_size=1)\n",
    "print(contexts)   # (6,2)\n",
    "\n",
    "# 맥락(contexts) : 예측할 단어의 주변 단어\n",
    "# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
    "# window_size=1 일 경우 : 주변 단어를 중간 단어에 앞,뒤로 1개만 사용\n",
    "# [[0 2]   : 'you', 'goodbye'\n",
    "#  [1 3]   : 'say', 'and'\n",
    "#  [2 4]   : 'goodbye', 'i'\n",
    "#  [3 1]   : 'and', 'say'\n",
    "#  [4 5]   : 'i', 'hello'\n",
    "#  [1 6]]  : 'say', '.'\n",
    "\n",
    "# window_size=2 일 경우 : : 주변 단어를 중간 단어에 앞,뒤로 2개 사용\n",
    "# [[0 1 3 4]\n",
    "#  [1 2 4 1]\n",
    "#  [2 3 1 5]\n",
    "#  [3 4 5 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(target)\n",
    "# 타깃(target) : 예측할 단어, 중간단어, 6개\n",
    "# ['say','goodbye','and','i','say','hello']\n",
    "# [1 2 3 4 1 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 맥락과 타깃을 원핫 표현으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 변환 함수\n",
    "\n",
    "# target [1 2 3 4 1 5]을 변환하는 경우를 주석으로 설명 \n",
    "def convert_one_hot(corpus, vocab_size):  # [1 2 3 4 1 5], 7\n",
    "    N = corpus.shape[0] # (6,) --> 6\n",
    "\n",
    "    if corpus.ndim == 1: # target [1 2 3 4 1 5], 1차원인경우 ==> 2차원으로 출력\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32) # 0으로 초기화된 (6,7) 2차원 배열 생성 \n",
    "        for idx, word_id in enumerate(corpus): # 6회 반복\n",
    "            one_hot[idx, word_id] = 1  # one_hot[0,1] = 1, [1,2]=1, [2,3] = 1,...,  [3,4],[4,1],[5,5] = 1...\n",
    "\n",
    "    elif corpus.ndim == 2: # contexts 2차원 인경우 ==> 3차원으로 출력\n",
    "        C = corpus.shape[1] # (6,2) --> 2\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32) # 0으로 초기화된 (6,2,7) 3차원 배열 생성 \n",
    "        for idx_0, word_ids in enumerate(corpus): # 6회\n",
    "            for idx_1, word_id in enumerate(word_ids): #  2회\n",
    "                one_hot[idx_0, idx_1, word_id] = 1  \n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "print(vocab_size)  # 7\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]]\n",
      "(6, 2, 7)\n"
     ]
    }
   ],
   "source": [
    "print(contexts)\n",
    "print(contexts.shape) # (6, 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n",
      "(6, 7)\n"
     ]
    }
   ],
   "source": [
    "print(target)\n",
    "print(target.shape)  # (6, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] CBOW 신경망 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]] (1, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]\n",
      " [0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]\n",
      " [0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]\n",
      " [0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]\n",
      " [0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]\n",
      " [0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]\n",
      " [0.59761571 0.73739479 0.54995818 0.37814734 0.3184111  0.13234083\n",
      "  0.42081886 0.23908142]] (7, 8)\n",
      "[[0.31565889 0.13655778 0.32991521 0.89250622 0.12661212 0.08338482\n",
      "  0.5215833  0.06512067]\n",
      " [0.75721382 0.5398176  0.51018399 0.46081092 0.11132111 0.95317476\n",
      "  0.07237367 0.15604987]\n",
      " [0.59197897 0.42977271 0.54788629 0.1473942  0.39783239 0.03686029\n",
      "  0.3635845  0.19978584]\n",
      " [0.31364304 0.82007435 0.0794864  0.15459752 0.66304579 0.70904678\n",
      "  0.86600638 0.40351552]\n",
      " [0.59419396 0.44295711 0.79126073 0.51417458 0.46781139 0.95664306\n",
      "  0.86249096 0.43431208]\n",
      " [0.17114683 0.04411914 0.56368927 0.78818436 0.24866155 0.01977524\n",
      "  0.30191801 0.28620236]\n",
      " [0.51346656 0.37971275 0.31509408 0.49337347 0.3123116  0.79131639\n",
      "  0.90920715 0.70116959]] (7, 8)\n",
      "---------------------------------------------------------------------- \n",
      " [[3.25730207 2.79301145 3.13751597 3.45104126 2.32759595 3.55020135\n",
      "  3.89716398 2.24615593]] (1, 8)\n",
      "[[0.31360875 0.43520046 0.23403275 0.22381953 0.85512666 0.56913311\n",
      "  0.47235791 0.74822609]\n",
      " [0.44695982 0.81655124 0.65005439 0.96380316 0.52473003 0.69968695\n",
      "  0.37891858 0.66418265]\n",
      " [0.67338059 0.6112896  0.37945258 0.15211651 0.72181821 0.52970371\n",
      "  0.43549058 0.21520546]\n",
      " [0.03714922 0.17163115 0.30425287 0.04136535 0.78962599 0.72674436\n",
      "  0.08608961 0.89494817]\n",
      " [0.28142087 0.62809848 0.57130404 0.08804557 0.37579726 0.86690166\n",
      "  0.49320004 0.54112953]\n",
      " [0.04920108 0.18066376 0.08460499 0.14335213 0.07177181 0.2136975\n",
      "  0.97875742 0.48601792]\n",
      " [0.91264011 0.58185179 0.02546255 0.70774614 0.98295959 0.05959144\n",
      "  0.94877403 0.19497205]]\n",
      "\n",
      "\n",
      "[[2.71436045 3.42528649 2.24916416 2.32024838 4.32182955 3.66545873\n",
      "  3.79358817 3.74468189]]\n",
      "[4 5 6]\n",
      "[4 5 6]\n",
      "[[0 0 0]] <class 'numpy.ndarray'>\n",
      "2.718281828459045\n",
      "2.718281828459045\n"
     ]
    }
   ],
   "source": [
    "from nn_layers import  MatMul, SoftmaxWithLoss, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  다중 분류 모델 : Softmax 사용\n",
    "class SimpleCBOW :\n",
    "    def __init__(self,vocab_size,hidden_size):  # 어휘수 : 7개, 은닉층의 뉴런 : 5\n",
    "        V,H = vocab_size,hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01*np.random.randn(V,H).astype('f')   # (7,5)\n",
    "        W_out = 0.01*np.random.randn(H,V).astype('f')  # (5,7)\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer0,self.in_layer1,self.out_layer]  \n",
    "        self.params,self.grads = [],[]\n",
    "        for layer in layers: # 4회\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # 인스턴스 변수 단어의 분산 표현을 저장한다.\n",
    "        self.word_vec = W_in\n",
    "        \n",
    "    def predict(self,contexts):  # contexts : (6,2,7)\n",
    "        \n",
    "        # (6,7) * (7,5) = (6,5)\n",
    "        h0 = self.in_layer0.forward(contexts[:,0])  # (6,7)으로 입력, 맥락의 첫번째 단어 \n",
    "        h1 = self.in_layer1.forward(contexts[:,1])  # (6,7)으로 입력, 맥락의 두번째 단어\n",
    "        \n",
    "        h = (h0 + h1) * 0.5  # 평균\n",
    "        \n",
    "        # (6,5) * (5,7) = (6,7)\n",
    "        score = self.out_layer.forward(h)\n",
    "        return self.loss_layer.softmax(score) # softmax()함수로 확률값으로 출력\n",
    "        \n",
    "    def forward(self,contexts,target):  # contexts : (6,2,7) , target : (6,7)\n",
    "        \n",
    "        # (6,7) * (7,5) = (6,5)\n",
    "        h0 = self.in_layer0.forward(contexts[:,0])  # (6,7)으로 입력, 맥락의 첫번째 단어 \n",
    "        h1 = self.in_layer1.forward(contexts[:,1])  # (6,7)으로 입력, 맥락의 두번째 단어\n",
    "        \n",
    "        h = (h0 + h1) * 0.5  # 평균\n",
    "        \n",
    "        # (6,5) * (5,7) = (6,7)\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score,target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer0.backward(da)\n",
    "        self.in_layer1.backward(da)\n",
    "        return None        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer 클래스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def remove_duplicate(params, grads):\n",
    "    '''\n",
    "    매개변수의 중복 제거 함수\n",
    "    매개변수 배열 중 중복되는 가중치를 하나로 모아\n",
    "    그 가중치에 대응하는 기울기를 더한다.\n",
    "    '''\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                # 가중치 공유 시\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  # 경사를 더함\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                # 가중치를 전치행렬로 공유하는 경우(weight tying)\n",
    "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
    "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg: break\n",
    "            if find_flg: break\n",
    "\n",
    "        if not find_flg: break\n",
    "\n",
    "    return params, grads\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = []\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            # 뒤섞기\n",
    "            idx = np.random.permutation(np.arange(data_size))\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "\n",
    "                # 기울기 구해 매개변수 갱신\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                \n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # 평가\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 손실 %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
    "                    self.loss_list.append(float(avg_loss))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = np.arange(len(self.loss_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label='train')\n",
    "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('손실')\n",
    "        plt.show()      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]] (6, 2, 7)\n",
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]] (6, 7)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "print(contexts,contexts.shape)\n",
    "print(target,target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
      "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
      "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
      "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
      "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
      "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
      "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
      "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
      "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
      "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
      "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
      "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
      "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
      "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
      "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
      "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
      "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
      "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
      "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
      "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
      "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
      "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
      "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
      "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
      "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 454 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 455 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 456 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 457 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 458 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 459 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 460 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 461 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 462 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 463 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 464 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 465 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 466 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 467 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 468 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 469 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 470 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 471 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 472 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 473 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 474 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 475 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 476 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 477 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 478 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 479 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 480 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 481 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 482 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 483 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 484 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 485 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 486 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 487 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 488 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 489 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 490 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 491 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 492 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 493 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 494 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 495 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 496 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 497 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 498 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 499 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 500 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 501 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 502 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 503 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 504 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 505 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 506 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 507 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 508 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 509 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 510 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 511 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 512 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 513 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 514 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 515 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 516 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 517 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 518 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 519 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 520 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 521 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 522 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 523 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 524 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 525 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 526 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 527 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 528 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 529 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 530 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 531 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 532 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 533 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 534 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 535 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 536 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 537 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 538 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 539 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 540 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 541 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 542 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 543 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 544 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 545 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 546 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 547 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 548 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 549 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 550 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 551 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 552 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 553 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 554 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 555 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 556 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 557 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 558 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 559 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 560 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 561 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 562 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 563 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 564 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 565 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 566 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 567 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 568 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 569 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 570 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 571 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 572 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 573 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 574 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 575 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 576 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 577 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 578 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 579 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 580 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 581 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 582 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 583 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 584 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 585 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 586 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 587 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 588 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 589 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 590 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 591 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 592 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 593 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 594 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 595 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 596 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 597 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 598 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 599 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 600 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 601 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 602 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 603 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 604 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 605 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 606 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 607 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 608 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 609 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 610 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 611 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 612 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 613 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 614 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 615 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 616 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 617 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 618 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 619 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 620 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 621 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 622 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 623 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 624 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 625 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 626 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 627 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 628 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 629 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 630 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 631 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 632 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 633 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 634 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 635 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 636 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 637 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 638 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 639 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 640 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 641 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 642 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 643 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 644 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 645 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 646 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 647 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 648 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 649 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 650 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 651 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 652 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 653 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 654 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 655 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 656 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 657 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 658 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 659 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 660 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 661 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 662 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 663 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 664 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 665 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 666 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 667 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 668 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 669 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 670 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 671 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 672 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 673 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 674 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 675 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 676 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 677 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 678 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 679 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 680 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 681 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 682 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 683 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 684 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 685 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 686 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 687 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 688 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 689 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 690 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 691 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 692 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 693 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 694 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 695 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 696 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 697 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 698 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 699 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 700 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 701 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 702 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 703 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 704 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 705 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 706 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 707 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 708 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 709 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 710 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 711 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 712 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 713 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 714 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 715 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 716 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 717 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 718 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 719 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 720 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 721 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 722 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 723 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 724 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 725 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 726 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 727 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 728 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 729 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 730 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 731 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 732 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 733 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 734 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 735 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 736 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 737 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 738 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 739 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 740 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 741 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 742 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 743 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 744 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 745 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 746 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 747 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 748 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 749 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 750 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 751 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 752 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 753 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 754 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 755 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 756 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 757 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 758 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 759 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 760 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 761 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 762 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 763 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 764 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 765 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 766 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 767 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 768 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 769 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 770 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 771 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 772 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 773 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 774 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 775 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 776 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 777 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 778 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 779 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 780 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 781 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 782 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 783 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 784 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 785 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 786 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 787 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 788 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 789 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 790 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 791 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 792 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 793 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 794 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 795 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 796 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 797 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 798 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 799 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 800 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 801 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 802 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 803 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 804 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 805 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 806 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 807 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 808 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 809 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 810 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 811 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 812 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 813 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 814 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 815 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 816 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 817 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 818 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 819 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 820 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 821 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 822 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 823 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 824 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 825 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 826 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 827 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 828 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 829 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 830 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 831 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 832 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 833 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 834 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 835 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 836 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 837 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 838 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 839 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 840 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 841 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 842 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 843 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 844 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 845 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 846 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
      "| 에폭 847 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 848 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 849 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 850 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 851 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 852 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 853 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 854 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 855 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 856 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 857 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 858 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 859 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 860 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 861 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 862 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 863 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 864 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 865 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 866 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 867 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 868 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 869 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 870 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 871 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 872 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 873 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 874 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 875 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 876 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 877 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 878 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 879 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 880 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 881 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 882 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 883 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 884 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 885 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 886 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 887 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 888 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 889 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 890 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 891 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 892 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 893 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 894 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 895 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 896 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 897 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 898 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 899 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 900 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 901 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 902 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 903 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 904 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 905 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 906 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 907 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 908 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 909 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 910 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 911 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 912 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 913 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 914 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 915 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 916 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 917 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 918 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 919 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 920 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 921 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 922 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 923 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 924 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 925 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 926 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 927 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 928 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 929 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 930 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 931 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 932 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 933 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 934 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 935 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 936 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 937 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 938 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 939 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 940 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 941 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 942 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 943 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 944 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 945 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 946 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 947 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 948 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 949 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 950 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 951 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 952 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 953 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 954 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 955 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 956 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 957 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 958 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 959 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 960 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 961 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 962 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 963 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 964 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 965 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 966 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 967 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 968 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 969 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 970 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 971 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 972 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 973 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 974 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 975 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 976 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 977 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 978 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 979 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 980 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 981 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 982 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 983 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 984 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 985 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 986 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 987 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 988 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 989 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 990 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 991 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 992 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 993 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 994 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 995 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 996 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 997 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 998 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 999 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 1000 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       you :  [-1.0353395 -1.0674376  1.5282999 -1.1268682  1.1389354]\n",
      "       say :  [ 1.0429101  0.9859242 -1.2797272  1.1959547 -1.1620303]\n",
      "   goodbye :  [-1.0321541  -0.947079    0.16667229 -0.8157775   0.8450924 ]\n",
      "       and :  [ 1.4197339  1.5976045 -0.9773591  0.6385246 -0.7155172]\n",
      "         i :  [-1.0178264  -0.9235093   0.14151503 -0.81678206  0.85243887]\n",
      "     hello :  [-1.0263427 -1.0789875  1.52817   -1.1264944  1.1395222]\n",
      "         . :  [-0.25316077 -0.5127753  -1.2382436   1.4284977  -1.3482543 ]\n"
     ]
    }
   ],
   "source": [
    "# W_in : 인스턴스 변수에 단어의 분산 표현\n",
    "word_vecs = model.word_vec   # (7,5)\n",
    "for word_id, word in id_to_word.items():\n",
    "    print('%10s : '%word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 및 정확도 평가`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.84079179e-03 7.45351307e-01 4.36989058e-04 2.33478074e-01\n",
      "  4.37046562e-04 6.27773937e-04 9.82801786e-03]\n",
      " [1.00651043e-02 7.38780043e-05 3.85322002e-01 3.11496397e-04\n",
      "  3.82469828e-01 2.11686406e-01 1.00712851e-02]\n",
      " [1.86591183e-02 5.74352471e-01 2.02077531e-03 3.81111333e-01\n",
      "  2.02211037e-03 3.36037709e-03 1.84738144e-02]\n",
      " [1.00651043e-02 7.38780043e-05 3.85322002e-01 3.11496397e-04\n",
      "  3.82469828e-01 2.11686406e-01 1.00712851e-02]\n",
      " [1.00289680e-02 7.42852036e-01 4.55287127e-04 2.35543263e-01\n",
      "  4.55241743e-04 6.49096699e-04 1.00161083e-02]\n",
      " [1.34137373e-02 2.80804046e-04 2.53108187e-01 1.45857672e-03\n",
      "  2.58488682e-01 4.60007133e-01 1.32428797e-02]]\n",
      "(6, 7)\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "h = model.predict(contexts)\n",
    "print(h)\n",
    "print(h.shape)  # (6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [1 2 3 4 1 5]\n",
      "predict: [1 2 1 2 1 5]\n",
      "정확도 : 0.6667\n"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "preds = np.argmax(h,1)\n",
    "t = np.argmax(target,1)\n",
    "print('target:',t)\n",
    "print('predict:',preds)\n",
    "\n",
    "accuracy = np.sum(np.equal(preds,t))/len(t)\n",
    "print('정확도 :', np.round(accuracy,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[preds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
