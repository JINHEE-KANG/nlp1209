{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 사용 Text 분류 모델 구현\n",
    ": Keras의 Embedding,LSTM,Dropout 계층 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Spam and Ham 분류 테스트 데이터 셋 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 5)\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... ham\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2 Unnamed: 2  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1    ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3    ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6    ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8   spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9   spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "10   ham  I'm gonna be home soon and i don't want to tal...        NaN   \n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...        NaN   \n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...        NaN   \n",
       "13   ham  I've been searching for the right words to tha...        NaN   \n",
       "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!        NaN   \n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...        NaN   \n",
       "16   ham                         Oh k...i'm watching here:)        NaN   \n",
       "17   ham  Eh u remember how 2 spell his name... Yes i di...        NaN   \n",
       "18   ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...        NaN   \n",
       "19  spam  England v Macedonia - dont miss the goals/team...        NaN   \n",
       "\n",
       "   Unnamed: 3 Unnamed: 4  \n",
       "0         NaN        NaN  \n",
       "1         NaN        NaN  \n",
       "2         NaN        NaN  \n",
       "3         NaN        NaN  \n",
       "4         NaN        NaN  \n",
       "5         NaN        NaN  \n",
       "6         NaN        NaN  \n",
       "7         NaN        NaN  \n",
       "8         NaN        NaN  \n",
       "9         NaN        NaN  \n",
       "10        NaN        NaN  \n",
       "11        NaN        NaN  \n",
       "12        NaN        NaN  \n",
       "13        NaN        NaN  \n",
       "14        NaN        NaN  \n",
       "15        NaN        NaN  \n",
       "16        NaN        NaN  \n",
       "17        NaN        NaN  \n",
       "18        NaN        NaN  \n",
       "19        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv',delimiter=',',encoding='latin-1')\n",
    "# ISO/IEC 8859-1, https://ko.wikipedia.org/wiki/ISO/IEC_8859-1\n",
    "print(df.shape)  # (5572, 5)\n",
    "print(df['v2'][0], df['v1'][0])  # ham\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불필요한 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham  Even my brother is not like to speak with me. ...\n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "10   ham  I'm gonna be home soon and i don't want to tal...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13   ham  I've been searching for the right words to tha...\n",
       "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16   ham                         Oh k...i'm watching here:)\n",
       "17   ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18   ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
       "19  spam  England v Macedonia - dont miss the goals/team..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\n",
    "df.head(20)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분포를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of ham and spam messages')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZwklEQVR4nO3de7RdZX3u8e9DQECBAiUgJGioxVbAKzFitZV6I9VaGO3B4pEaKxrLodWeYVWw5yhqGdLq0apVWnoxQas01VrTC7WIYusRiaFeIiAlA5DERBKQqxeO4O/8Md+UyWbvPXcga++d7O9njDXWnO+c71zvnGvt9az5zstOVSFJ0mR2m+kGSJJmP8NCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLDQlCVZkeQPZui1k+RDSW5Nsmac6S9P8oWZaNuOlOT4JBtnuh3SWIbFTizJDUluSvKIXtkrk1w6g80alWcCzwMWVtWSmW6MNNcYFju/3YHXznQjtleSedtZ5dHADVX1vVG0R9LkDIud3zuB30uy/9gJSRYlqSS798ouTfLKNvzyJP83yXuS3JbkuiQ/18o3JNmSZNmYxR6U5OIkdyb5fJJH95b9s23ad5Nck+TFvWkrkpyX5J+TfA/4xXHae1iS1a3++iSvauWnAX8BPD3JXUneOtHGSPKu1lV1fZJf6pX/ZpKrW7uvS/Lq3rTjk2xM8oa2zpuTnJTkBUn+s7XnTZO85guTfCXJHW27nT3Oe7AsyY1Jbk7y+73pe7dtc2uSq4CnTvI6ae/VliS3J/l6kmN62/dPJ3lv3tvadkeSK5L8fG/a2Un+NslHWt11SR6b5Kz2WhuSPH+Sdt2Q5PWtPd9L8pdJDklyUVveZ5Ic0Jv/uCRfbJ+5ryU5vjft5e39ubO9hy9t5T/d1un2tg3/ZorrtneSlW37Xt3e44296Ycl+USSre31XtObtiTJ2rbcm5K8e6JtMCdUlY+d9AHcADwX+DvgD1rZK4FL2/AioIDde3UuBV7Zhl8O3AP8JjAP+APgRuADwJ7A84E7gX3a/Cva+C+06e8FvtCmPQLY0Ja1O/AU4Gbg6F7d24Fn0P1I2Wuc9fk88EFgL+BJwFbgOb22fmGSbfFy4EfAq9q6nA5sAtKmvxB4DBDgWcD3gae0ace37fBmYI+2jK3AR4F9gaOBHwI/NcFrHw88vq3XE4CbgJPGvAd/DuwNPBG4G3hcm34u8O/AgcDhwDeAjRO8zgnAFcD+bT0eBxw69N606acCP9nem9cB39n2HgBnt/U7oU2/ALge+P3e9rh+4HP4JeAQYAGwBfgP4MmtLZ8F3tLmXQDcArygba/ntfH5dJ+hO4CfafMeyn2fn4+19uzWPh/PnOK6nUv3uToAWAh8fdv2bcu6or3vDwN+CrgOOKFNvwz4jTa8D3DcTP/Nz+j3zUw3wMdDePPuC4tj6L6I57P9YXFtb9rj2/yH9MpuAZ7UhlcAF/am7QPcS/cl9+vAv49p35/1viRWABdMsi6Ht2Xt2yt7B7Ci19ahsFjfG394W5dHTjD/3wOvbcPHAz8A5rXxfVvdp/Xmv4IWAFN4X/4YeM+Y92Bhb/oa4JQ2fB2wtDdtOROHxbOB/wSOA3YbM23C92aCZd0KPLENnw1c3Jv2IuCucbbH/pN8Dl/aG/8EcF5v/HeAv2/DbwQ+PKb+p4FldGFxG/BrwN5j5rkAOL+/HSfZ/v11+68v/zb+Su4Li6cBN46pexbwoTb8b8BbgYMeyt/prvKwG2oXUFXfAP4ROPNBVL+pN/yDtryxZfv0xjf0Xvcu4LvAYXTHFJ7WuhZuS3Ib8FLgkePVHcdhwHer6s5e2bfofolO1Xd6bft+G9wHIMkvJflS61K6je6X7UG9urdU1b1t+AftebLt8F+SPC3J51pXxu3Ab41Z9v3aRrdXs21Zh3H/7fKtiVauqj4L/Andnt9NSc5Psl9vloneG5K8rnXD3N7W/yfGtHHsut48zvYYd/0nqD/Rtns0cPKYz8kz6faQvkf3o+O3gM1J/inJz7Z6b6Dbm1qT5Mokr9i28IF1G7t9+8OPBg4b05Y30e0hAZwGPBb4ZpIvJ/nlSdZ/l2dY7DreQtdd0P9y3XYw+OG9sv6X94Nx+LaBJPvQdZ9sovsj/HxV7d977FNVp/fqTnaL403AgUn27ZU9Cvj2Q2wvSfak+7X7Lrq9pv2Bf6b78tkRPgqspvsV/xPAn27HsjfT26Z06zyhqnpfVR1L1zX2WOD1vcnjvjetD/+NwIuBA9r6374dbdyRNtDtWfQ/J4+oqnMBqurTVfU8ui6ob9J131FV36mqV1XVYcCrgQ+24xhD67aZrvtpm/623kDXvdZvy75V9YL2mtdW1UuAg4E/BD6e3pmHc41hsYuoqvXA3wCv6ZVtpfuyPTXJvPZr7DEP8aVekOSZSR4GvB24vKo20O3ZPDbJbyTZoz2emuRxU2z/BuCLwDuS7JXkCXS/7P76IbYXuv7oPemOQ9yT7sD3hAdsH4R96faKfphkCfDft6PuKuCsJAckWUjXZTOutj2flmQPuh8CP6TratpmovdmX7pjMluB3ZO8GdiPmfER4EVJTmifyb3SnWCwsB0U/5X2hXw3XVfYvQBJTm7bB7pupmrThtatv30XAL/dm7YGuCPJG9uB8HlJjkny1PaapyaZX1U/puseg/tv7znFsNi1vI2u37fvVXS/Pm+h+zX6xYf4Gh+l24v5LnAsXVcTrfvo+cApdHsJ36H7Nbbndiz7JXR9/JuAT9Id77j4IbZ3W9teQ/fFcSvdl/nqh7rcnv8BvC3JnXQHS1dtR9230nU9XQ/8K/DhSebdj+6X9q2tzi10e0vbjPve0B0TuIjueMe36EJmsi7BkWnhdSJdd8/W1o7X030X7UZ3gHoT3To8i27bQneW2OVJ7qJ7715bVdczvG5vAzbSbd/PAB+nCyJaN9uL6E6muJ7uhIy/oOvGAlgKXNle8710x5l+uMM2xk5m25kiknZiSVbQHbj9XzPdltksyel0X/rPmum27Gzcs5C0y0pyaJJnJNktyc/Q7bl8cqbbtTPafXgWSdppPYzuFO4j6I47XEh3LY+2k91QkqRBdkNJkgaNtBsqyQ10tyC4F7inqhYnOZDuFM9FdFd+vriqbm3zn0V3uuS9wGuq6tOt/Fi6K1T3pjs//rU1sEt00EEH1aJFi3b4OknSruyKK664uarmjy2fjmMWv1hVN/fGzwQuqapzk5zZxt+Y5Ci60y6Pprvq8jNJHttObzuP7jYIX6ILi6V0p8tNaNGiRaxdu3bHr40k7cKSjHsXgZnohjoRWNmGVwIn9covrKq72/nT64ElSQ4F9quqy9rexAW9OpKkaTDqsCjgX9ttg5e3skOqajNAez64lS/g/hfTbGxlC9rw2PIHSLK83VJ47datW3fgakjS3DbqbqhnVNWmJAcDFyf55iTzjnefmpqk/IGFVefT3ZmSxYsXe5qXJO0gI92zqKpN7XkL3YUwS+julnkodBfM0N37Hro9hv5NvhbSXfa/kfvfCGxbuSRpmowsLJI8YtsdRNuNwZ5P949dVtPdu572/Kk2vBo4JcmeSY4AjgTWtK6qO9P9d60AL+vVkSRNg1F2Qx0CfLL7fmd34KNV9S9JvgysSvevMm8ETgaoqiuTrAKuoruL5Bm9++mfzn2nzl7EwJlQkqQda5e9gnvx4sXlqbOStH2SXFFVi8eWewW3JGmQYSFJGuRdZydw7OsvmOkmaBa64p0vm+kmSDPCPQtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNGnlYJJmX5CtJ/rGNH5jk4iTXtucDevOelWR9kmuSnNArPzbJujbtfUky6nZLku4zHXsWrwWu7o2fCVxSVUcCl7RxkhwFnAIcDSwFPphkXqtzHrAcOLI9lk5DuyVJzUjDIslC4IXAX/SKTwRWtuGVwEm98gur6u6quh5YDyxJciiwX1VdVlUFXNCrI0maBqPes/hj4A3Aj3tlh1TVZoD2fHArXwBs6M23sZUtaMNjyx8gyfIka5Os3bp16w5ZAUnSCMMiyS8DW6rqiqlWGaesJil/YGHV+VW1uKoWz58/f4ovK0kasvsIl/0M4FeSvADYC9gvyUeAm5IcWlWbWxfTljb/RuDwXv2FwKZWvnCccknSNBnZnkVVnVVVC6tqEd2B689W1anAamBZm20Z8Kk2vBo4JcmeSY6gO5C9pnVV3ZnkuHYW1Mt6dSRJ02CUexYTORdYleQ04EbgZICqujLJKuAq4B7gjKq6t9U5HVgB7A1c1B6SpGkyLWFRVZcCl7bhW4DnTDDfOcA545SvBY4ZXQslSZPxCm5J0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjRoZGGRZK8ka5J8LcmVSd7ayg9McnGSa9vzAb06ZyVZn+SaJCf0yo9Nsq5Ne1+SjKrdkqQHGuWexd3As6vqicCTgKVJjgPOBC6pqiOBS9o4SY4CTgGOBpYCH0wyry3rPGA5cGR7LB1huyVJY4wsLKpzVxvdoz0KOBFY2cpXAie14ROBC6vq7qq6HlgPLElyKLBfVV1WVQVc0KsjSZoGIz1mkWRekq8CW4CLq+py4JCq2gzQng9usy8ANvSqb2xlC9rw2PLxXm95krVJ1m7dunWHroskzWUjDYuqureqngQspNtLOGaS2cc7DlGTlI/3eudX1eKqWjx//vztbq8kaXzTcjZUVd0GXEp3rOGm1rVEe97SZtsIHN6rthDY1MoXjlMuSZomozwban6S/dvw3sBzgW8Cq4FlbbZlwKfa8GrglCR7JjmC7kD2mtZVdWeS49pZUC/r1ZEkTYPdR7jsQ4GV7Yym3YBVVfWPSS4DViU5DbgROBmgqq5Msgq4CrgHOKOq7m3LOh1YAewNXNQekqRpMrKwqKqvA08ep/wW4DkT1DkHOGec8rXAZMc7JEkj5BXckqRBhoUkaZBhIUkaNKWwSHLJVMokSbumSQ9wJ9kLeDhwULvh37YL5PYDDhtx2yRJs8TQ2VCvBn6XLhiu4L6wuAP4wOiaJUmaTSYNi6p6L/DeJL9TVe+fpjZJkmaZKV1nUVXvT/JzwKJ+naq6YETtkiTNIlMKiyQfBh4DfBXYdlX1ttuFS5J2cVO9gnsxcFT7fxKSpDlmqtdZfAN45CgbIkmavaa6Z3EQcFWSNXT/LhWAqvqVkbRKkjSrTDUszh5lIyRJs9tUz4b6/KgbIkmavaZ6NtSd3PevTB8G7AF8r6r2G1XDJEmzx1T3LPbtjyc5CVgyigZJkmafB3XX2ar6e+DZO7YpkqTZaqrdUL/aG92N7roLr7mQpDliqmdDvag3fA9wA3DiDm+NJGlWmuoxi98cdUMkSbPXVP/50cIkn0yyJclNST6RZOGoGydJmh2meoD7Q8Bquv9rsQD4h1YmSZoDphoW86vqQ1V1T3usAOaPsF2SpFlkqmFxc5JTk8xrj1OBW0bZMEnS7DHVsHgF8GLgO8Bm4L8BHvSWpDliqqfOvh1YVlW3AiQ5EHgXXYhIknZxU92zeMK2oACoqu8CTx5NkyRJs81Uw2K3JAdsG2l7FlPdK5Ek7eSm+oX/f4AvJvk43W0+XgycM7JWSZJmlalewX1BkrV0Nw8M8KtVddVIWyZJmjWm3JXUwsGAkKQ56EHdolySNLcYFpKkQYaFJGnQyMIiyeFJPpfk6iRXJnltKz8wycVJrm3P/VNyz0qyPsk1SU7olR+bZF2b9r4kGVW7JUkPNMo9i3uA11XV44DjgDOSHAWcCVxSVUcCl7Rx2rRTgKOBpcAHk8xryzoPWA4c2R5LR9huSdIYIwuLqtpcVf/Rhu8Erqa7vfmJwMo220rgpDZ8InBhVd1dVdcD64ElSQ4F9quqy6qqgAt6dSRJ02BajlkkWUR3e5DLgUOqajN0gQIc3GZbAGzoVdvYyha04bHl473O8iRrk6zdunXrDl0HSZrLRh4WSfYBPgH8blXdMdms45TVJOUPLKw6v6oWV9Xi+fP9dxuStKOMNCyS7EEXFH9dVX/Xim9qXUu05y2tfCNweK/6QmBTK184TrkkaZqM8myoAH8JXF1V7+5NWg0sa8PLgE/1yk9JsmeSI+gOZK9pXVV3JjmuLfNlvTqSpGkwyjvHPgP4DWBdkq+2sjcB5wKrkpwG3AicDFBVVyZZRXdLkXuAM6rq3lbvdGAFsDdwUXtIkqbJyMKiqr7A+McbAJ4zQZ1zGOdutlW1Fjhmx7VOkrQ9vIJbkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNGllYJPmrJFuSfKNXdmCSi5Nc254P6E07K8n6JNckOaFXfmySdW3a+5JkVG2WJI1vlHsWK4ClY8rOBC6pqiOBS9o4SY4CTgGObnU+mGReq3MesBw4sj3GLlOSNGIjC4uq+jfgu2OKTwRWtuGVwEm98gur6u6quh5YDyxJciiwX1VdVlUFXNCrI0maJtN9zOKQqtoM0J4PbuULgA29+Ta2sgVteGz5uJIsT7I2ydqtW7fu0IZL0lw2Ww5wj3ccoiYpH1dVnV9Vi6tq8fz583dY4yRprpvusLipdS3Rnre08o3A4b35FgKbWvnCccolSdNousNiNbCsDS8DPtUrPyXJnkmOoDuQvaZ1Vd2Z5Lh2FtTLenUkSdNk91EtOMnHgOOBg5JsBN4CnAusSnIacCNwMkBVXZlkFXAVcA9wRlXd2xZ1Ot2ZVXsDF7WHJGkajSwsquolE0x6zgTznwOcM075WuCYHdg0SdJ2mi0HuCVJs5hhIUkaZFhIkgYZFpKkQYaFJGnQyM6GkjQ6N77t8TPdBM1Cj3rzupEt2z0LSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYMMC0nSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA0yLCRJgwwLSdIgw0KSNMiwkCQNMiwkSYN2mrBIsjTJNUnWJzlzptsjSXPJThEWSeYBHwB+CTgKeEmSo2a2VZI0d+wUYQEsAdZX1XVV9f+AC4ETZ7hNkjRn7D7TDZiiBcCG3vhG4GljZ0qyHFjeRu9Kcs00tG0uOAi4eaYbMRvkXctmugl6ID+f27wlO2Ipjx6vcGcJi/G2QD2goOp84PzRN2duSbK2qhbPdDuk8fj5nB47SzfURuDw3vhCYNMMtUWS5pydJSy+DByZ5IgkDwNOAVbPcJskac7YKbqhquqeJL8NfBqYB/xVVV05w82aS+za02zm53MapOoBXf+SJN3PztINJUmaQYaFJGmQYTGHJVmU5Bsz3Q5Js59hIUkaZFhoXpI/T3Jlkn9NsneSVyX5cpKvJflEkocDJFmR5Lwkn0tyXZJnJfmrJFcnWTHD66FdQJJHJPmn9tn7RpJfT3JDkj9MsqY9frrN+6Iklyf5SpLPJDmklZ+dZGX7PN+Q5FeT/FGSdUn+JckeM7uWOyfDQkcCH6iqo4HbgF8D/q6qnlpVTwSuBk7rzX8A8GzgfwL/ALwHOBp4fJInTWO7tWtaCmyqqidW1THAv7TyO6pqCfAnwB+3si8Ax1XVk+nuF/eG3nIeA7yQ7h5yHwE+V1WPB37QyrWdDAtdX1VfbcNXAIuAY5L8e5J1wEvpwmCbf6jufOt1wE1Vta6qfgxc2epKD8U64LltT+Lnq+r2Vv6x3vPT2/BC4NPtc/p67v85vaiqftSWN4/7Qmcdfk4fFMNCd/eG76W7UHMF8Nvtl9hbgb3Gmf/HY+r+mJ3kIk/NXlX1n8CxdF/q70jy5m2T+rO15/cDf9I+p69mnM9p+yHzo7rvgjI/pw+SYaHx7Atsbn27L53pxmjuSHIY8P2q+gjwLuApbdKv954va8M/AXy7DXs74BEzYTWe/w1cDnyL7hfevjPbHM0hjwfemeTHwI+A04GPA3smuZzuB+5L2rxnA3+b5NvAl4Ajpr+5c4e3+5A0qyW5AVhcVf7PihlkN5QkaZB7FpKkQe5ZSJIGGRaSpEGGhSRpkGEhPURJ7tqOec9O8nujWr40KoaFJGmQYSGNwER3RG2emOSzSa5N8qpende3u/1+PclbZ6DZ0oQMC2k0Jrsj6hPo7nz6dODNSQ5L8ny6OwAvAZ4EHJvkF6a3ydLEvN2HNBoLgb9JcijwMOD63rRPVdUPgB8k+RxdQDwTeD7wlTbPPnTh8W/T12RpYoaFNBrvB95dVauTHE93H6Ntxl4JW0CAd1TVn01L66TtZDeUNBqT3RH1xCR7JflJ4Hjgy8CngVck2QcgyYIkB09XY6Uh7llID93Dk2zsjb+bye+Iugb4J+BRwNurahOwKcnjgMuSANwFnApsGX3zpWHeG0qSNMhuKEnSIMNCkjTIsJAkDTIsJEmDDAtJ0iDDQpI0yLCQJA36/x/W84YoIJYvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.v1)\n",
    "plt.xlabel('Label')\n",
    "plt.title('Number of ham and spam messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y 값을 0, 1로 변환 : LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df.v2\n",
    "Y = df.v1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)    # Y 값이 0,1로 변환, Logistic Regression, sigmoid사용\n",
    "Y = Y.reshape(-1,1)\n",
    "print(Y.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900,) (1672,) (3900, 1) (1672, 1)\n"
     ]
    }
   ],
   "source": [
    "### train 과 test 데이터 셋으로 분리\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3) # 70:30\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장을 토큰화 처리, 패딩, 데이터셋의 길이를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "\n",
    "# tf.keras.preprocessing.text.Tokenizer(\n",
    "#     num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
    "#     split=' ', char_level=False, oov_token=None, document_count=0, **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 150)\n",
      "7413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  24, 232, 241],\n",
       "       [  0,   0,   0, ...,   6, 315,  50],\n",
       "       [  0,   0,   0, ...,  68, 150, 186],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  12, 279,  69],\n",
       "       [  0,   0,   0, ..., 109,   7, 182],\n",
       "       [  0,   0,   0, ...,   3, 315,  29]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#토큰나이저를 시행하여 단어를 숫자값, 인덱스로 변환하여 저장\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 150  # 데이터 셋의 길이\n",
    "\n",
    "\n",
    "tok = Tokenizer(num_words=max_words) # 가장 빈도가 높은 1000 개의 단어들만 사용하여 토큰화\n",
    "\n",
    "# 단어 인덱스를 구축\n",
    "tok.fit_on_texts(X_train)  # 범위 : 0 ~ 999\n",
    "\n",
    "# 문자열을 정수 인덱스의 리스트로 변환\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "# sequences\n",
    "\n",
    "\n",
    "# 벡터 표현을 얻음\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)   # 신경망에 입력할 X값이다\n",
    "print(sequences_matrix.shape) # (3900, 150)\n",
    "# sequences_matrix\n",
    "\n",
    "word_to_index = tok.word_index\n",
    "# print(word_to_index)\n",
    "vocab_size = len(word_to_index)\n",
    "print(vocab_size) # 7339\n",
    "\n",
    "sequences_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 신경망 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "# tf.keras.layers.Embedding(\n",
    "#     input_dim, output_dim, embeddings_initializer='uniform',\n",
    "#     embeddings_regularizer=None, activity_regularizer=None,\n",
    "#     embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs\n",
    "# )\n",
    "\n",
    "# input_dim : input_dim   , D  , max_words : 1000\n",
    "# output_dim : hidden_size , H , 50\n",
    "# input_length : sequence_length , T : max_len:150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSTM 1층을 사용하여 신경망을 구현  : Accuracy : 0.982\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(max_words,50,input_length=max_len), # 3차원으로 출력, (None, 150, 50)\n",
    "#     tf.keras.layers.LSTM(32,return_sequences=True),  # 3차원으로 출력, (None, 150, 32) \n",
    "#     tf.keras.layers.Dense(32,activation='relu'),     # 3차원으로 출력, (None, 150, 32)\n",
    "#     tf.keras.layers.Dropout(rate=0.5),               # 3차원으로 출력, (None, 150, 32)\n",
    "#     tf.keras.layers.Flatten(),                       # 2차원으로 출력, (None, 4800)\n",
    "#     tf.keras.layers.Dense(1,activation='sigmoid')    # 2차원으로 출력, (None, 1)\n",
    "# ])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 150, 32)           10624     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 70,033\n",
      "Trainable params: 70,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM 2층 을 사용하여 신경망을 구현  :    [ Accuracy :  0.983]  # 2층의 정확도가 약간 높다\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words,50,input_length=max_len), # 3차원으로 출력, (None, 150, 50) \n",
    "    tf.keras.layers.LSTM(32,return_sequences=True),  # 3차원으로 출력, (None, 150, 32) \n",
    "    tf.keras.layers.LSTM(32),                        # 2차원으로 출력, (None,  32) \n",
    "    tf.keras.layers.Dense(32,activation='relu'),     # 2원으로 출력,   (None,  32)\n",
    "    tf.keras.layers.Dropout(rate=0.5),               # 2차원으로 출력, (None,  32)\n",
    "    # tf.keras.layers.Flatten(),                     \n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')    # 2차원으로 출력, (None, 1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "# RMSProp : https://forensics.tistory.com/28\n",
    "# RMSprop 알고리즘은 Adadelta와 마찬가지로 Adagrad에서 학습률이 급격하게 감소하는 문제를 해결 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3120 samples, validate on 780 samples\n",
      "Epoch 1/10\n",
      "3120/3120 [==============================] - 8s 3ms/sample - loss: 0.4729 - acc: 0.8301 - val_loss: 0.2609 - val_acc: 0.8808\n",
      "Epoch 2/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.2104 - acc: 0.9423 - val_loss: 0.1446 - val_acc: 0.9692\n",
      "Epoch 3/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.1040 - acc: 0.9798 - val_loss: 0.1084 - val_acc: 0.9692\n",
      "Epoch 4/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.0671 - acc: 0.9869 - val_loss: 0.1236 - val_acc: 0.9628\n",
      "Epoch 5/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.0483 - acc: 0.9897 - val_loss: 0.0781 - val_acc: 0.9756\n",
      "Epoch 6/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.0389 - acc: 0.9917 - val_loss: 0.0844 - val_acc: 0.9782\n",
      "Epoch 7/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.0281 - acc: 0.9926 - val_loss: 0.0943 - val_acc: 0.9782\n",
      "Epoch 8/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.0238 - acc: 0.9942 - val_loss: 0.1105 - val_acc: 0.9756\n",
      "Epoch 9/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.0158 - acc: 0.9962 - val_loss: 0.1322 - val_acc: 0.9744\n",
      "Epoch 10/10\n",
      "3120/3120 [==============================] - 7s 2ms/sample - loss: 0.0145 - acc: 0.9965 - val_loss: 0.1446 - val_acc: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a793a6f908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "model.fit(sequences_matrix,Y_train,batch_size=128, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1672, 150)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  13,  19,   5],\n",
       "       [  0,   0,   0, ...,  67,   8,   4],\n",
       "       [  0,   0,   0, ..., 114,  15, 855],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  78, 744, 145],\n",
       "       [  0,   0,   0, ..., 388,  12,  15],\n",
       "       [  0,   0,   0, ..., 217, 473, 133]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터세의 벡터를 구함\n",
    "\n",
    "# 문자열을 정수 인덱스의 리스트로 변환\n",
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "# test_sequences\n",
    "\n",
    "# 벡터 표현을 얻음\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)   \n",
    "print(test_sequences_matrix.shape) # (1672, 150)\n",
    "test_sequences_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672/1672 [==============================] - 2s 1ms/sample - loss: 0.0848 - acc: 0.9856\n"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.085\n",
      "  Accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00012975]], dtype=float32), array([0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "preds = model.predict(test_sequences_matrix[0].reshape(1,-1)) # test_sequences_matrix[0]은 1차원이므로\n",
    "preds,Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 34,  3, 60, 13, 19,  5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.99970955]], dtype=float32), array([1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_sequences_matrix[17].reshape(1,-1)) # test_sequences_matrix[0]은 1차원이므로\n",
    "preds,Y_test[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  17,   19,   25,   42,   80,   84,   86,   92,  110,  119,  122,\n",
       "        123,  125,  130,  136,  146,  153,  165,  170,  171,  184,  193,\n",
       "        203,  206,  208,  210,  211,  214,  217,  219,  229,  235,  237,\n",
       "        240,  244,  247,  263,  272,  300,  318,  337,  351,  352,  361,\n",
       "        362,  365,  368,  372,  381,  414,  418,  423,  426,  429,  432,\n",
       "        449,  467,  475,  477,  482,  483,  487,  496,  498,  499,  507,\n",
       "        509,  517,  538,  542,  547,  548,  558,  565,  566,  571,  578,\n",
       "        588,  594,  598,  603,  613,  621,  625,  644,  665,  673,  674,\n",
       "        682,  683,  695,  697,  703,  716,  719,  723,  725,  742,  758,\n",
       "        771,  782,  790,  822,  828,  837,  842,  845,  847,  850,  851,\n",
       "        852,  853,  864,  867,  888,  918,  927,  932,  934,  948,  954,\n",
       "        959,  965,  967,  978,  989,  997, 1012, 1023, 1026, 1034, 1037,\n",
       "       1052, 1069, 1073, 1074, 1079, 1084, 1090, 1091, 1092, 1098, 1101,\n",
       "       1110, 1129, 1148, 1150, 1164, 1178, 1180, 1191, 1193, 1206, 1220,\n",
       "       1222, 1226, 1233, 1242, 1243, 1246, 1271, 1275, 1280, 1282, 1285,\n",
       "       1286, 1298, 1310, 1313, 1315, 1322, 1339, 1342, 1352, 1371, 1378,\n",
       "       1383, 1405, 1413, 1428, 1429, 1430, 1436, 1440, 1442, 1463, 1468,\n",
       "       1480, 1482, 1483, 1485, 1490, 1497, 1498, 1499, 1532, 1533, 1537,\n",
       "       1555, 1558, 1564, 1569, 1574, 1575, 1606, 1613, 1621, 1626, 1632,\n",
       "       1639, 1640, 1642, 1651, 1653, 1665, 1667], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.where(Y_test==1)   # 답이 1인 인덱스\n",
    "ones[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99970955]] [1]\n",
      "[[0.9996898]] [1]\n",
      "[[0.99971277]] [1]\n",
      "[[0.9996784]] [1]\n",
      "[[0.9945655]] [1]\n",
      "[[0.99967563]] [1]\n",
      "[[0.9996674]] [1]\n",
      "[[0.9995708]] [1]\n",
      "[[0.9982431]] [1]\n",
      "[[0.99955565]] [1]\n",
      "[[0.99966884]] [1]\n",
      "[[0.999561]] [1]\n",
      "[[0.9996879]] [1]\n",
      "[[0.9982198]] [1]\n",
      "[[8.317396e-05]] [1]\n",
      "[[0.9995449]] [1]\n",
      "[[0.9994542]] [1]\n",
      "[[0.99968207]] [1]\n",
      "[[0.9994892]] [1]\n",
      "[[0.99971396]] [1]\n",
      "[[0.9986753]] [1]\n",
      "[[0.99938726]] [1]\n",
      "[[0.9996427]] [1]\n",
      "[[0.99965906]] [1]\n",
      "[[0.99956733]] [1]\n",
      "[[0.9995609]] [1]\n",
      "[[0.99950886]] [1]\n",
      "[[0.9994466]] [1]\n",
      "[[0.99955815]] [1]\n",
      "[[0.9995672]] [1]\n",
      "[[0.99965763]] [1]\n",
      "[[8.545548e-06]] [1]\n",
      "[[0.9996252]] [1]\n",
      "[[0.9996668]] [1]\n",
      "[[0.9995734]] [1]\n",
      "[[0.99889225]] [1]\n",
      "[[0.9997019]] [1]\n",
      "[[0.05767461]] [1]\n",
      "[[0.99966645]] [1]\n",
      "[[0.99962544]] [1]\n",
      "[[0.9945655]] [1]\n",
      "[[0.9997248]] [1]\n",
      "[[0.99949944]] [1]\n",
      "[[0.99964166]] [1]\n",
      "[[0.99966097]] [1]\n",
      "[[0.9995732]] [1]\n",
      "[[1.4807086e-05]] [1]\n",
      "[[0.99961436]] [1]\n",
      "[[0.9996749]] [1]\n",
      "[[0.9983645]] [1]\n",
      "[[0.9975689]] [1]\n",
      "[[0.999683]] [1]\n",
      "[[0.9995553]] [1]\n",
      "[[0.99966383]] [1]\n",
      "[[0.9993262]] [1]\n",
      "[[0.9996624]] [1]\n",
      "[[0.99785465]] [1]\n",
      "[[0.7117409]] [1]\n",
      "[[0.9997147]] [1]\n",
      "[[0.9996885]] [1]\n",
      "[[0.36843204]] [1]\n",
      "[[0.99956006]] [1]\n",
      "[[0.99969506]] [1]\n",
      "[[0.9996481]] [1]\n",
      "[[0.9996699]] [1]\n",
      "[[0.99968624]] [1]\n",
      "[[0.9996817]] [1]\n",
      "[[0.99968433]] [1]\n",
      "[[0.9995871]] [1]\n",
      "[[0.9991773]] [1]\n",
      "[[0.99973077]] [1]\n",
      "[[0.96424574]] [1]\n",
      "[[0.9996439]] [1]\n",
      "[[0.9995708]] [1]\n",
      "[[0.9994466]] [1]\n",
      "[[0.0001131]] [1]\n",
      "[[0.99970835]] [1]\n",
      "[[0.99954104]] [1]\n",
      "[[0.9996463]] [1]\n",
      "[[0.99965847]] [1]\n",
      "[[0.9996364]] [1]\n",
      "[[0.9986299]] [1]\n",
      "[[0.99967813]] [1]\n",
      "[[0.9996319]] [1]\n",
      "[[0.9997305]] [1]\n",
      "[[0.9997248]] [1]\n",
      "[[0.9996612]] [1]\n",
      "[[0.9995701]] [1]\n",
      "[[0.9989944]] [1]\n",
      "[[0.9996495]] [1]\n",
      "[[0.9993936]] [1]\n",
      "[[0.9995993]] [1]\n",
      "[[0.99971646]] [1]\n",
      "[[0.9980388]] [1]\n",
      "[[0.99967515]] [1]\n",
      "[[0.9996443]] [1]\n",
      "[[0.9996878]] [1]\n",
      "[[0.9996151]] [1]\n",
      "[[0.9987457]] [1]\n",
      "[[0.999647]] [1]\n",
      "[[0.99959713]] [1]\n",
      "[[0.79522866]] [1]\n",
      "[[0.9873798]] [1]\n",
      "[[0.999731]] [1]\n",
      "[[0.9995115]] [1]\n",
      "[[1.7054746e-05]] [1]\n",
      "[[0.99968827]] [1]\n",
      "[[0.9993874]] [1]\n",
      "[[8.234941e-06]] [1]\n",
      "[[0.99964786]] [1]\n",
      "[[0.99966073]] [1]\n",
      "[[0.9994535]] [1]\n",
      "[[0.99959356]] [1]\n",
      "[[0.9996854]] [1]\n",
      "[[0.99964607]] [1]\n",
      "[[0.99968076]] [1]\n",
      "[[0.9996859]] [1]\n",
      "[[0.9995608]] [1]\n",
      "[[0.99966776]] [1]\n",
      "[[0.99931324]] [1]\n",
      "[[0.95987284]] [1]\n",
      "[[0.9996488]] [1]\n",
      "[[0.9992681]] [1]\n",
      "[[0.9997162]] [1]\n",
      "[[0.99963915]] [1]\n",
      "[[0.99968684]] [1]\n",
      "[[0.9995414]] [1]\n",
      "[[0.99938107]] [1]\n",
      "[[0.9995752]] [1]\n",
      "[[0.99962795]] [1]\n",
      "[[0.99956673]] [1]\n",
      "[[0.9996755]] [1]\n",
      "[[0.9873798]] [1]\n",
      "[[0.999602]] [1]\n",
      "[[0.9993831]] [1]\n",
      "[[0.99956673]] [1]\n",
      "[[0.9996784]] [1]\n",
      "[[0.99951243]] [1]\n",
      "[[0.00340975]] [1]\n",
      "[[0.99966824]] [1]\n",
      "[[0.9996184]] [1]\n",
      "[[0.99959356]] [1]\n",
      "[[0.9997013]] [1]\n",
      "[[0.99935824]] [1]\n",
      "[[0.9978453]] [1]\n",
      "[[0.9996878]] [1]\n",
      "[[0.02037874]] [1]\n",
      "[[0.99815446]] [1]\n",
      "[[0.99969685]] [1]\n",
      "[[0.99904567]] [1]\n",
      "[[0.9993042]] [1]\n",
      "[[0.9995473]] [1]\n",
      "[[0.9996749]] [1]\n",
      "[[0.99964213]] [1]\n",
      "[[0.9997048]] [1]\n",
      "[[0.99967194]] [1]\n",
      "[[0.9996911]] [1]\n",
      "[[0.9495266]] [1]\n",
      "[[0.9994929]] [1]\n",
      "[[0.9991345]] [1]\n",
      "[[0.998697]] [1]\n",
      "[[0.9996803]] [1]\n",
      "[[0.99948406]] [1]\n",
      "[[1.2845177e-05]] [1]\n",
      "[[0.99971455]] [1]\n",
      "[[0.9996487]] [1]\n",
      "[[0.99968934]] [1]\n",
      "[[0.9994555]] [1]\n",
      "[[0.01375645]] [1]\n",
      "[[0.9995734]] [1]\n",
      "[[0.999683]] [1]\n",
      "[[0.99959284]] [1]\n",
      "[[0.9996289]] [1]\n",
      "[[0.9996575]] [1]\n",
      "[[0.99929404]] [1]\n",
      "[[0.9996495]] [1]\n",
      "[[0.99934584]] [1]\n",
      "[[0.9994916]] [1]\n",
      "[[0.99968433]] [1]\n",
      "[[0.99959654]] [1]\n",
      "[[0.99944144]] [1]\n",
      "[[0.99929285]] [1]\n",
      "[[0.99960583]] [1]\n",
      "[[0.9996989]] [1]\n",
      "[[0.99963546]] [1]\n",
      "[[0.9996766]] [1]\n",
      "[[0.99966395]] [1]\n",
      "[[0.9995778]] [1]\n",
      "[[0.9996978]] [1]\n",
      "[[0.999683]] [1]\n",
      "[[0.99969876]] [1]\n",
      "[[0.9995672]] [1]\n",
      "[[0.9995431]] [1]\n",
      "[[0.99730957]] [1]\n",
      "[[0.9996766]] [1]\n",
      "[[0.9997323]] [1]\n",
      "[[0.999608]] [1]\n",
      "[[0.9996321]] [1]\n",
      "[[0.9997179]] [1]\n",
      "[[0.99969673]] [1]\n",
      "[[0.9996735]] [1]\n",
      "[[0.99968815]] [1]\n",
      "[[0.9996712]] [1]\n",
      "[[0.9978453]] [1]\n",
      "[[0.99964535]] [1]\n",
      "[[0.99956733]] [1]\n",
      "[[0.99929667]] [1]\n",
      "[[0.9997305]] [1]\n",
      "[[0.9996044]] [1]\n",
      "[[0.9991634]] [1]\n",
      "[[0.99968076]] [1]\n",
      "[[0.9996463]] [1]\n",
      "[[0.99963164]] [1]\n",
      "[[0.99384034]] [1]\n",
      "[[0.561772]] [1]\n",
      "[[0.9996394]] [1]\n"
     ]
    }
   ],
   "source": [
    "for one in ones[0]:\n",
    "    preds = model.predict(test_sequences_matrix[one].reshape(1,-1))\n",
    "    print(preds,Y_test[one])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
