{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"07_기계번역.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HtHF88M8SXZk"},"source":["# 기계 번역(Neural Machine Translation)\n","## [1] 영한 번역기 구현 :   Character-Level 번역기 만들기"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XWn6aM4tSXZm","colab":{},"executionInfo":{"status":"ok","timestamp":1600603819775,"user_tz":-540,"elapsed":2360,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["import pandas as pd\n","import urllib3\n","import zipfile\n","import shutil\n","import os\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VkxtFa8sSXZz","colab":{},"executionInfo":{"status":"ok","timestamp":1600603820481,"user_tz":-540,"elapsed":3062,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["http = urllib3.PoolManager()\n","url ='http://www.manythings.org/anki/kor-eng.zip'\n","filename = 'kor-eng.zip'\n","path = os.getcwd()\n","zipfilename = os.path.join(path, filename)\n","with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n","    shutil.copyfileobj(r, out_file)\n","\n","with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n","    zip_ref.extractall(path)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gk8Sy8bYSXZ7","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603820482,"user_tz":-540,"elapsed":3052,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"dca161f2-94c0-4e36-a783-ed8fa3243c4f"},"source":["lines= pd.read_csv('kor.txt', names=['src', 'tar'], sep='\\t', index_col =False)\n","lines.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3638, 2)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RidzraTvSXaj","colab":{"base_uri":"https://localhost:8080/","height":491},"executionInfo":{"status":"ok","timestamp":1600603820483,"user_tz":-540,"elapsed":3044,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"f6945e1b-5d5e-4a76-f0d5-db5575cca405"},"source":["lines.head(15)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>tar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>가.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>안녕.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>뛰어!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run.</td>\n","      <td>뛰어.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Who?</td>\n","      <td>누구?</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Wow!</td>\n","      <td>우와!</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Fire!</td>\n","      <td>쏴!</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Help!</td>\n","      <td>도와줘!</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Jump!</td>\n","      <td>점프!</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Jump.</td>\n","      <td>점프해.</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Wait!</td>\n","      <td>기다려!</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Wait!</td>\n","      <td>잠깐!</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Wait.</td>\n","      <td>기다려.</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Begin.</td>\n","      <td>시작해.</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Hello!</td>\n","      <td>안녕!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       src   tar\n","0      Go.    가.\n","1      Hi.   안녕.\n","2     Run!   뛰어!\n","3     Run.   뛰어.\n","4     Who?   누구?\n","5     Wow!   우와!\n","6    Fire!    쏴!\n","7    Help!  도와줘!\n","8    Jump!   점프!\n","9    Jump.  점프해.\n","10   Wait!  기다려!\n","11   Wait!   잠깐!\n","12   Wait.  기다려.\n","13  Begin.  시작해.\n","14  Hello!   안녕!"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mYTJqAO8SXaw","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1600603820484,"user_tz":-540,"elapsed":3036,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"b05fd2bc-8f59-4b86-ea68-620d3f8fb79d"},"source":["# target 컬럼 'tar'에 '\\t'와 '\\n'을 앞 뒤로 추가\n","lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n","lines[2000:2100]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>tar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2000</th>\n","      <td>Somebody was talking to Tom.</td>\n","      <td>\\t 누군가 톰한테 말을 걸고 있었어. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2001</th>\n","      <td>Someone ate all my cupcakes.</td>\n","      <td>\\t 누가 내 컵케익 다 먹었어 \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2002</th>\n","      <td>That's why I can't help you.</td>\n","      <td>\\t 이게 바로 내가 널 도와줄 수 없는 이유야. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2003</th>\n","      <td>The cat is still very young.</td>\n","      <td>\\t 그 고양이는 아직도 많이 어려. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2004</th>\n","      <td>There's a full moon tonight.</td>\n","      <td>\\t 오늘밤은 보름달이 떴어. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2095</th>\n","      <td>I should've bought more food.</td>\n","      <td>\\t 내가 먹을 것을 더 샀어야 했는데. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2096</th>\n","      <td>I think that Tom is offended.</td>\n","      <td>\\t 내 생각에 톰은 기분이 상해있어. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2097</th>\n","      <td>I think that Tom is sensible.</td>\n","      <td>\\t 톰은 예민한 것 같아. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2098</th>\n","      <td>I tried to act appropriately.</td>\n","      <td>\\t 난 적절하게 처신하려고 노력했어. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>2099</th>\n","      <td>I used to be a heroin addict.</td>\n","      <td>\\t 나는 한때 헤로인 중독자였어. \\n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>"],"text/plain":["                                src                             tar\n","2000   Somebody was talking to Tom.        \\t 누군가 톰한테 말을 걸고 있었어. \\n\n","2001   Someone ate all my cupcakes.            \\t 누가 내 컵케익 다 먹었어 \\n\n","2002   That's why I can't help you.  \\t 이게 바로 내가 널 도와줄 수 없는 이유야. \\n\n","2003   The cat is still very young.         \\t 그 고양이는 아직도 많이 어려. \\n\n","2004   There's a full moon tonight.             \\t 오늘밤은 보름달이 떴어. \\n\n","...                             ...                             ...\n","2095  I should've bought more food.       \\t 내가 먹을 것을 더 샀어야 했는데. \\n\n","2096  I think that Tom is offended.        \\t 내 생각에 톰은 기분이 상해있어. \\n\n","2097  I think that Tom is sensible.              \\t 톰은 예민한 것 같아. \\n\n","2098  I tried to act appropriately.        \\t 난 적절하게 처신하려고 노력했어. \\n\n","2099  I used to be a heroin addict.          \\t 나는 한때 헤로인 중독자였어. \\n\n","\n","[100 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LpVBxjtiSXbj","colab":{},"executionInfo":{"status":"ok","timestamp":1600603820485,"user_tz":-540,"elapsed":3035,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["# 'src'와 'tar'의 글자 집합 구축\n","src_vocab=set()\n","for line in lines.src:   # 1줄씩 읽음\n","    for char in line:    # 1개의 글자씩 읽음\n","        src_vocab.add(char)\n","# print(src_vocab)  # 영어의 글자 수\n","\n","tar_vocab=set()\n","for line in lines.tar:\n","    for char in line:\n","        tar_vocab.add(char)\n","# print(tar_vocab)   # 한국어의 글자 수"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"B0heErOdSXb8","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600603820486,"user_tz":-540,"elapsed":3027,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"9488efe5-5789-44c2-aa1b-0564961f46b7"},"source":["src_vocab_size = len(src_vocab)+1\n","tar_vocab_size = len(tar_vocab)+1\n","print(src_vocab_size)\n","print(tar_vocab_size)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["75\n","912\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1wurtoiWSXcA","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600603820486,"user_tz":-540,"elapsed":3018,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"3c17ddf0-facf-42cb-cfc4-ae7a0159b025"},"source":["src_vocab = sorted(list(src_vocab))\n","tar_vocab = sorted(list(tar_vocab))\n","print(src_vocab[45:75])\n","print(tar_vocab[45:75])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'ï']\n","['간', '갇', '갈', '감', '갑', '값', '갔', '강', '갖', '같', '개', '객', '갰', '걀', '걔', '거', '걱', '건', '걷', '걸', '검', '겁', '것', '게', '겐', '겠', '겨', '격', '겪', '견']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hm8XLW_WSXcD","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600603820487,"user_tz":-540,"elapsed":3010,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"bd96e901-6ac3-4486-8061-69a6f3df3a6a"},"source":["src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n","tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n","print(src_to_index)\n","print(tar_to_index)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '?': 22, 'A': 23, 'B': 24, 'C': 25, 'D': 26, 'E': 27, 'F': 28, 'G': 29, 'H': 30, 'I': 31, 'J': 32, 'K': 33, 'L': 34, 'M': 35, 'N': 36, 'O': 37, 'P': 38, 'Q': 39, 'R': 40, 'S': 41, 'T': 42, 'U': 43, 'V': 44, 'W': 45, 'Y': 46, 'a': 47, 'b': 48, 'c': 49, 'd': 50, 'e': 51, 'f': 52, 'g': 53, 'h': 54, 'i': 55, 'j': 56, 'k': 57, 'l': 58, 'm': 59, 'n': 60, 'o': 61, 'p': 62, 'q': 63, 'r': 64, 's': 65, 't': 66, 'u': 67, 'v': 68, 'w': 69, 'x': 70, 'y': 71, 'z': 72, '°': 73, 'ï': 74}\n","{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '%': 6, '(': 7, ')': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'H': 29, 'M': 30, 'N': 31, 'T': 32, 'a': 33, 'd': 34, 'h': 35, 'i': 36, 'm': 37, 'o': 38, 'p': 39, 'r': 40, 't': 41, 'y': 42, '°': 43, '가': 44, '각': 45, '간': 46, '갇': 47, '갈': 48, '감': 49, '갑': 50, '값': 51, '갔': 52, '강': 53, '갖': 54, '같': 55, '개': 56, '객': 57, '갰': 58, '걀': 59, '걔': 60, '거': 61, '걱': 62, '건': 63, '걷': 64, '걸': 65, '검': 66, '겁': 67, '것': 68, '게': 69, '겐': 70, '겠': 71, '겨': 72, '격': 73, '겪': 74, '견': 75, '결': 76, '겼': 77, '경': 78, '계': 79, '고': 80, '곡': 81, '곤': 82, '곧': 83, '골': 84, '곰': 85, '곱': 86, '곳': 87, '공': 88, '과': 89, '관': 90, '광': 91, '괜': 92, '괴': 93, '굉': 94, '교': 95, '구': 96, '국': 97, '군': 98, '굳': 99, '굴': 100, '굶': 101, '굼': 102, '굽': 103, '궁': 104, '권': 105, '귀': 106, '귄': 107, '규': 108, '그': 109, '극': 110, '근': 111, '글': 112, '금': 113, '급': 114, '긋': 115, '긍': 116, '기': 117, '긴': 118, '길': 119, '깊': 120, '까': 121, '깎': 122, '깐': 123, '깔': 124, '깜': 125, '깡': 126, '깨': 127, '꺼': 128, '꺾': 129, '껍': 130, '껏': 131, '껐': 132, '께': 133, '껴': 134, '꼈': 135, '꼬': 136, '꼴': 137, '꼼': 138, '꽃': 139, '꽉': 140, '꽤': 141, '꾸': 142, '꾼': 143, '꿇': 144, '꿈': 145, '꿔': 146, '꿨': 147, '뀌': 148, '끄': 149, '끈': 150, '끊': 151, '끌': 152, '끓': 153, '끔': 154, '끗': 155, '끙': 156, '끝': 157, '끼': 158, '낀': 159, '낄': 160, '낌': 161, '나': 162, '낙': 163, '낚': 164, '난': 165, '날': 166, '낡': 167, '남': 168, '납': 169, '났': 170, '낭': 171, '낮': 172, '낯': 173, '내': 174, '낸': 175, '낼': 176, '냄': 177, '냈': 178, '냉': 179, '냐': 180, '냥': 181, '너': 182, '넌': 183, '널': 184, '넓': 185, '넘': 186, '넛': 187, '넣': 188, '네': 189, '넷': 190, '녀': 191, '녁': 192, '년': 193, '념': 194, '녕': 195, '노': 196, '녹': 197, '논': 198, '놀': 199, '농': 200, '높': 201, '놓': 202, '놔': 203, '놨': 204, '뇌': 205, '누': 206, '눅': 207, '눈': 208, '눠': 209, '눴': 210, '뉴': 211, '늄': 212, '느': 213, '늑': 214, '는': 215, '늘': 216, '늙': 217, '능': 218, '늦': 219, '니': 220, '닌': 221, '님': 222, '다': 223, '닥': 224, '닦': 225, '단': 226, '닫': 227, '달': 228, '닮': 229, '담': 230, '답': 231, '당': 232, '대': 233, '댔': 234, '더': 235, '덕': 236, '던': 237, '덜': 238, '덤': 239, '덥': 240, '데': 241, '덴': 242, '도': 243, '독': 244, '돈': 245, '돌': 246, '돕': 247, '동': 248, '돼': 249, '됐': 250, '되': 251, '된': 252, '될': 253, '됩': 254, '두': 255, '둑': 256, '둔': 257, '둘': 258, '둠': 259, '둬': 260, '뒀': 261, '뒤': 262, '드': 263, '득': 264, '든': 265, '듣': 266, '들': 267, '듯': 268, '등': 269, '디': 270, '딘': 271, '딨': 272, '따': 273, '딱': 274, '딸': 275, '땅': 276, '땋': 277, '때': 278, '떠': 279, '떡': 280, '떤': 281, '떨': 282, '떴': 283, '떻': 284, '또': 285, '똑': 286, '뚱': 287, '뛰': 288, '뜨': 289, '뜰': 290, '뜻': 291, '라': 292, '락': 293, '란': 294, '랄': 295, '람': 296, '랍': 297, '랐': 298, '랑': 299, '래': 300, '랜': 301, '램': 302, '랩': 303, '랬': 304, '략': 305, '량': 306, '러': 307, '럭': 308, '런': 309, '럴': 310, '럼': 311, '럽': 312, '렀': 313, '렁': 314, '렇': 315, '레': 316, '렌': 317, '렛': 318, '려': 319, '력': 320, '련': 321, '렵': 322, '렸': 323, '령': 324, '례': 325, '로': 326, '록': 327, '론': 328, '롭': 329, '뢰': 330, '료': 331, '루': 332, '룹': 333, '류': 334, '륙': 335, '륜': 336, '륭': 337, '르': 338, '른': 339, '를': 340, '름': 341, '릅': 342, '릎': 343, '리': 344, '린': 345, '릴': 346, '림': 347, '립': 348, '마': 349, '막': 350, '만': 351, '많': 352, '말': 353, '맙': 354, '맛': 355, '망': 356, '맞': 357, '맡': 358, '매': 359, '맥': 360, '맨': 361, '맷': 362, '머': 363, '먹': 364, '먼': 365, '멀': 366, '멈': 367, '멋': 368, '멍': 369, '메': 370, '멕': 371, '멜': 372, '며': 373, '면': 374, '명': 375, '몇': 376, '모': 377, '목': 378, '몰': 379, '몸': 380, '못': 381, '묘': 382, '무': 383, '묵': 384, '묶': 385, '문': 386, '묻': 387, '물': 388, '뭇': 389, '뭐': 390, '뭔': 391, '뭘': 392, '므': 393, '미': 394, '민': 395, '믿': 396, '밀': 397, '밌': 398, '밍': 399, '밑': 400, '바': 401, '박': 402, '밖': 403, '반': 404, '받': 405, '발': 406, '밝': 407, '밟': 408, '밤': 409, '밥': 410, '방': 411, '배': 412, '백': 413, '뱀': 414, '버': 415, '벅': 416, '번': 417, '벌': 418, '범': 419, '법': 420, '벗': 421, '벙': 422, '베': 423, '벼': 424, '벽': 425, '변': 426, '별': 427, '병': 428, '보': 429, '복': 430, '본': 431, '볼': 432, '봄': 433, '봅': 434, '봇': 435, '봉': 436, '봐': 437, '봤': 438, '부': 439, '북': 440, '분': 441, '불': 442, '붉': 443, '붐': 444, '붕': 445, '붙': 446, '브': 447, '블': 448, '비': 449, '빈': 450, '빌': 451, '빙': 452, '빛': 453, '빠': 454, '빨': 455, '빴': 456, '빵': 457, '빼': 458, '뺄': 459, '뻔': 460, '뻤': 461, '뽀': 462, '뽑': 463, '뿌': 464, '뿐': 465, '쁘': 466, '쁜': 467, '쁠': 468, '삐': 469, '사': 470, '삭': 471, '산': 472, '살': 473, '삶': 474, '삼': 475, '샀': 476, '상': 477, '새': 478, '색': 479, '샌': 480, '생': 481, '샤': 482, '샴': 483, '서': 484, '석': 485, '선': 486, '설': 487, '섬': 488, '섭': 489, '섯': 490, '섰': 491, '성': 492, '세': 493, '센': 494, '셈': 495, '셔': 496, '셜': 497, '셨': 498, '소': 499, '속': 500, '손': 501, '솔': 502, '송': 503, '쇠': 504, '수': 505, '숙': 506, '순': 507, '숟': 508, '술': 509, '숨': 510, '쉬': 511, '쉽': 512, '슈': 513, '스': 514, '슨': 515, '슬': 516, '습': 517, '승': 518, '시': 519, '식': 520, '신': 521, '실': 522, '싫': 523, '심': 524, '십': 525, '싱': 526, '싶': 527, '싸': 528, '쌉': 529, '써': 530, '썩': 531, '썼': 532, '썽': 533, '쏘': 534, '쏠': 535, '쏴': 536, '쓰': 537, '쓱': 538, '쓴': 539, '쓸': 540, '씀': 541, '씨': 542, '씩': 543, '씬': 544, '씻': 545, '아': 546, '악': 547, '안': 548, '앉': 549, '않': 550, '알': 551, '앓': 552, '암': 553, '압': 554, '앗': 555, '았': 556, '앙': 557, '앞': 558, '애': 559, '액': 560, '앨': 561, '앵': 562, '야': 563, '약': 564, '얀': 565, '얇': 566, '양': 567, '얗': 568, '얘': 569, '어': 570, '억': 571, '언': 572, '얻': 573, '얼': 574, '엄': 575, '업': 576, '없': 577, '엇': 578, '었': 579, '엌': 580, '에': 581, '엔': 582, '엘': 583, '여': 584, '역': 585, '연': 586, '열': 587, '염': 588, '엽': 589, '였': 590, '영': 591, '옆': 592, '예': 593, '옛': 594, '오': 595, '옥': 596, '온': 597, '올': 598, '옮': 599, '옳': 600, '옷': 601, '옹': 602, '와': 603, '완': 604, '왔': 605, '왜': 606, '외': 607, '왼': 608, '요': 609, '욕': 610, '용': 611, '우': 612, '운': 613, '울': 614, '움': 615, '웃': 616, '워': 617, '원': 618, '월': 619, '웠': 620, '웨': 621, '위': 622, '윈': 623, '윗': 624, '윙': 625, '유': 626, '육': 627, '윤': 628, '으': 629, '은': 630, '을': 631, '음': 632, '읍': 633, '응': 634, '의': 635, '이': 636, '익': 637, '인': 638, '일': 639, '읽': 640, '잃': 641, '임': 642, '입': 643, '있': 644, '잊': 645, '자': 646, '작': 647, '잔': 648, '잖': 649, '잘': 650, '잠': 651, '잡': 652, '잤': 653, '장': 654, '재': 655, '잭': 656, '쟁': 657, '저': 658, '적': 659, '전': 660, '절': 661, '젊': 662, '점': 663, '접': 664, '정': 665, '제': 666, '젝': 667, '젠': 668, '젯': 669, '져': 670, '졌': 671, '조': 672, '족': 673, '존': 674, '졸': 675, '좀': 676, '종': 677, '좋': 678, '좌': 679, '죄': 680, '죠': 681, '주': 682, '죽': 683, '준': 684, '줄': 685, '중': 686, '줘': 687, '줬': 688, '쥐': 689, '즈': 690, '즉': 691, '즐': 692, '즘': 693, '증': 694, '지': 695, '직': 696, '진': 697, '질': 698, '집': 699, '짓': 700, '짖': 701, '짜': 702, '짝': 703, '짧': 704, '째': 705, '쨌': 706, '쩔': 707, '쩡': 708, '쪄': 709, '쪘': 710, '쪼': 711, '쪽': 712, '쫓': 713, '쯤': 714, '찌': 715, '찍': 716, '찔': 717, '찡': 718, '찢': 719, '차': 720, '착': 721, '찬': 722, '찮': 723, '찰': 724, '참': 725, '찼': 726, '창': 727, '찾': 728, '채': 729, '책': 730, '챌': 731, '챘': 732, '처': 733, '척': 734, '천': 735, '철': 736, '첫': 737, '청': 738, '체': 739, '쳐': 740, '쳤': 741, '초': 742, '촌': 743, '총': 744, '최': 745, '추': 746, '축': 747, '출': 748, '춤': 749, '충': 750, '춰': 751, '췄': 752, '취': 753, '츠': 754, '측': 755, '치': 756, '칙': 757, '친': 758, '칠': 759, '침': 760, '칩': 761, '카': 762, '캐': 763, '커': 764, '컨': 765, '컴': 766, '컵': 767, '케': 768, '켓': 769, '켜': 770, '켤': 771, '켰': 772, '코': 773, '콜': 774, '콥': 775, '콩': 776, '쾅': 777, '쿠': 778, '쿨': 779, '퀴': 780, '큐': 781, '크': 782, '큰': 783, '큼': 784, '키': 785, '킬': 786, '킹': 787, '타': 788, '탁': 789, '탄': 790, '탈': 791, '탐': 792, '탑': 793, '탓': 794, '탔': 795, '탕': 796, '태': 797, '택': 798, '터': 799, '턱': 800, '턴': 801, '테': 802, '텐': 803, '토': 804, '톰': 805, '톱': 806, '통': 807, '퇴': 808, '투': 809, '트': 810, '특': 811, '튼': 812, '틀': 813, '티': 814, '틱': 815, '틴': 816, '팀': 817, '팅': 818, '파': 819, '판': 820, '팔': 821, '팠': 822, '패': 823, '퍼': 824, '펐': 825, '페': 826, '펙': 827, '펜': 828, '펭': 829, '펴': 830, '편': 831, '평': 832, '폐': 833, '포': 834, '폭': 835, '폰': 836, '표': 837, '푸': 838, '푹': 839, '풀': 840, '품': 841, '풍': 842, '퓨': 843, '프': 844, '픈': 845, '플': 846, '픔': 847, '피': 848, '필': 849, '핑': 850, '하': 851, '학': 852, '한': 853, '할': 854, '함': 855, '합': 856, '항': 857, '해': 858, '핸': 859, '햄': 860, '했': 861, '행': 862, '향': 863, '햿': 864, '허': 865, '헉': 866, '헌': 867, '험': 868, '헤': 869, '헬': 870, '헷': 871, '혀': 872, '현': 873, '혈': 874, '혐': 875, '협': 876, '혔': 877, '형': 878, '혜': 879, '호': 880, '혹': 881, '혼': 882, '홉': 883, '홋': 884, '화': 885, '확': 886, '환': 887, '활': 888, '황': 889, '회': 890, '획': 891, '효': 892, '후': 893, '훈': 894, '훌': 895, '훔': 896, '훨': 897, '휘': 898, '휴': 899, '흐': 900, '흔': 901, '흘': 902, '흙': 903, '흠': 904, '흡': 905, '흥': 906, '희': 907, '흰': 908, '히': 909, '힌': 910, '힘': 911}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q6lgAf0DSXcf","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603820488,"user_tz":-540,"elapsed":3002,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"9b7f9ebf-cf84-4721-bc27-4eff9f769db6"},"source":["encoder_input = []\n","for line in lines.src: # 입력 영어 데이터에서 1줄씩 문장을 읽음\n","    temp_X = []\n","    for w in line:     #각 줄에서 1개씩 글자를 읽음\n","        temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n","    encoder_input.append(temp_X)\n","print(encoder_input[:5])  # 5개 샘플 출력"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[[29, 61, 9], [30, 55, 9], [40, 67, 60, 2], [40, 67, 60, 9], [45, 54, 61, 22]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nhKrM0eaSXc_","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603820488,"user_tz":-540,"elapsed":2993,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"bebe7865-8a2e-4279-8819-7ef76ae35eb1"},"source":["decoder_input = []\n","for line in lines.tar: # 출력 한국어 데이터에서 1줄씩 문장을 읽음\n","    temp_X = []\n","    for w in line:\n","        temp_X.append(tar_to_index[w])\n","    decoder_input.append(temp_X)\n","print(decoder_input[:5])  # 5개 샘플 출력"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[1, 3, 44, 11, 3, 2], [1, 3, 548, 195, 11, 3, 2], [1, 3, 288, 570, 4, 3, 2], [1, 3, 288, 570, 11, 3, 2], [1, 3, 206, 96, 24, 3, 2]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"toKvk4Y9SXdR","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603820489,"user_tz":-540,"elapsed":2985,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"3a096532-1f43-4c96-e342-8137f5f6bf0b"},"source":["# 'tar' 한국어 문장의 맨앞의 '\\t'(인코딩 값:1)를 모두 제거한다 \n","decoder_target = []\n","for line in lines.tar:\n","    t=0\n","    temp_X = []\n","    for w in line:\n","        if t>0:\n","            temp_X.append(tar_to_index[w])\n","        t=t+1\n","    decoder_target.append(temp_X)\n","print(decoder_target[:5])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[[3, 44, 11, 3, 2], [3, 548, 195, 11, 3, 2], [3, 288, 570, 4, 3, 2], [3, 288, 570, 11, 3, 2], [3, 206, 96, 24, 3, 2]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qzItvuJWSXdY","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600603820490,"user_tz":-540,"elapsed":2975,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"66bbcd4e-3a2c-47e3-9e97-b57451324c66"},"source":["# 영어와 한국어 문장의 최대 길이를 구한다\n","max_src_len = max([len(line) for line in lines.src])\n","max_tar_len = max([len(line) for line in lines.tar])\n","print(max_src_len)\n","print(max_tar_len)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["537\n","300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cncNsU8PSXdc","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600603820490,"user_tz":-540,"elapsed":2966,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"d20a510a-bb24-4d21-dc7f-2e114c080a41"},"source":["# 최대 길이를 10으로 나누어 사용 (학습 시간 단축)\n","max_src_len //= 10\n","max_tar_len //= 10\n","print(max_src_len)  # 53\n","print(max_tar_len)  # 30  \n","encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n","decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n","decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["53\n","30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vBrEcyhuSXdp","colab":{},"executionInfo":{"status":"ok","timestamp":1600603820967,"user_tz":-540,"elapsed":3441,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["# 원핫 벡터\n","encoder_input = to_categorical(encoder_input)\n","decoder_input = to_categorical(decoder_input)\n","decoder_target = to_categorical(decoder_target)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4xVsjwZiSXdu"},"source":["### seq2seq 모델 구현"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h_nYF-iMSXdv","colab":{},"executionInfo":{"status":"ok","timestamp":1600603820969,"user_tz":-540,"elapsed":3441,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n","from tensorflow.keras.models import Model\n","import numpy as np"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lbXAvKhxSXd1","colab":{},"executionInfo":{"status":"ok","timestamp":1600603821931,"user_tz":-540,"elapsed":4402,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["encoder_inputs = Input(shape=(None, src_vocab_size))\n","encoder_lstm = LSTM(units=256, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n","encoder_states = [state_h, state_c]\n","# LSTM은 바닐라 RNN과는 달리 상태가 두 개 : 은닉 상태와 셀 상태."],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pPO8-Ho2SXd7","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"ok","timestamp":1600603821932,"user_tz":-540,"elapsed":4394,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"65bdee79-1463-496d-dd3e-d43f12f76fc1"},"source":["decoder_inputs = Input(shape=(None, tar_vocab_size))\n","decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n","decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n","decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n","decoder_outputs = decoder_softmax_layer(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n","model.summary()\n","\n","# 글자  레벨이므로  Encoder 측에 워드임베딩을 위한 Embedding 계층을 사용하지 않았음"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, 75)]   0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None, 912)]  0                                            \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 256), (None, 339968      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 256),  1197056     input_2[0][0]                    \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 912)    234384      lstm_1[0][0]                     \n","==================================================================================================\n","Total params: 1,771,408\n","Trainable params: 1,771,408\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Plp5hX84SXd_","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600603883661,"user_tz":-540,"elapsed":66114,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"3f9e1bae-0269-46fb-d186-9571e01903b6"},"source":["model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","46/46 [==============================] - 2s 39ms/step - loss: 2.7830 - val_loss: 4.3016\n","Epoch 2/50\n","46/46 [==============================] - 1s 24ms/step - loss: 2.3705 - val_loss: 4.3215\n","Epoch 3/50\n","46/46 [==============================] - 1s 24ms/step - loss: 2.2180 - val_loss: 4.5484\n","Epoch 4/50\n","46/46 [==============================] - 1s 25ms/step - loss: 2.0430 - val_loss: 3.5706\n","Epoch 5/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.8526 - val_loss: 3.4046\n","Epoch 6/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.7611 - val_loss: 3.3528\n","Epoch 7/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.6694 - val_loss: 3.3579\n","Epoch 8/50\n","46/46 [==============================] - 1s 25ms/step - loss: 1.6450 - val_loss: 3.3291\n","Epoch 9/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.5610 - val_loss: 3.2837\n","Epoch 10/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.5192 - val_loss: 3.2462\n","Epoch 11/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.4796 - val_loss: 3.1605\n","Epoch 12/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.4415 - val_loss: 3.1854\n","Epoch 13/50\n","46/46 [==============================] - 1s 25ms/step - loss: 1.4068 - val_loss: 3.1719\n","Epoch 14/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.3707 - val_loss: 3.1233\n","Epoch 15/50\n","46/46 [==============================] - 1s 25ms/step - loss: 1.3378 - val_loss: 3.0758\n","Epoch 16/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.3055 - val_loss: 3.0318\n","Epoch 17/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.2741 - val_loss: 3.0604\n","Epoch 18/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.2457 - val_loss: 3.0408\n","Epoch 19/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.2180 - val_loss: 3.0997\n","Epoch 20/50\n","46/46 [==============================] - 1s 25ms/step - loss: 1.1914 - val_loss: 2.9442\n","Epoch 21/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.1718 - val_loss: 3.0247\n","Epoch 22/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.1409 - val_loss: 2.9380\n","Epoch 23/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.1188 - val_loss: 3.0088\n","Epoch 24/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.0986 - val_loss: 2.9092\n","Epoch 25/50\n","46/46 [==============================] - 1s 25ms/step - loss: 1.0761 - val_loss: 2.9414\n","Epoch 26/50\n","46/46 [==============================] - 1s 24ms/step - loss: 1.0571 - val_loss: 2.9206\n","Epoch 27/50\n","46/46 [==============================] - 1s 25ms/step - loss: 1.0351 - val_loss: 2.9123\n","Epoch 28/50\n","46/46 [==============================] - 1s 25ms/step - loss: 1.0141 - val_loss: 2.9912\n","Epoch 29/50\n","46/46 [==============================] - 1s 25ms/step - loss: 0.9970 - val_loss: 2.9400\n","Epoch 30/50\n","46/46 [==============================] - 1s 25ms/step - loss: 0.9757 - val_loss: 3.0856\n","Epoch 31/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.9559 - val_loss: 2.9718\n","Epoch 32/50\n","46/46 [==============================] - 1s 25ms/step - loss: 0.9380 - val_loss: 2.9227\n","Epoch 33/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.9205 - val_loss: 3.0805\n","Epoch 34/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.9002 - val_loss: 3.0030\n","Epoch 35/50\n","46/46 [==============================] - 1s 25ms/step - loss: 0.8813 - val_loss: 3.0061\n","Epoch 36/50\n","46/46 [==============================] - 1s 25ms/step - loss: 0.8651 - val_loss: 2.9545\n","Epoch 37/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.8476 - val_loss: 2.9221\n","Epoch 38/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.8322 - val_loss: 2.8605\n","Epoch 39/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.8144 - val_loss: 2.9596\n","Epoch 40/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.7958 - val_loss: 2.9586\n","Epoch 41/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.7844 - val_loss: 3.0697\n","Epoch 42/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.7801 - val_loss: 3.1041\n","Epoch 43/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.7684 - val_loss: 3.1077\n","Epoch 44/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.7493 - val_loss: 3.1246\n","Epoch 45/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.7240 - val_loss: 3.0703\n","Epoch 46/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.7059 - val_loss: 3.0789\n","Epoch 47/50\n","46/46 [==============================] - 1s 25ms/step - loss: 0.6906 - val_loss: 3.1663\n","Epoch 48/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.6742 - val_loss: 3.1350\n","Epoch 49/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.6592 - val_loss: 3.1381\n","Epoch 50/50\n","46/46 [==============================] - 1s 24ms/step - loss: 0.6448 - val_loss: 3.1237\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f375a75fd68>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cnyz3JU_SXeE","colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"status":"ok","timestamp":1600603883662,"user_tz":-540,"elapsed":66106,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"af4786cc-9502-4354-c0f5-386182e5a8ab"},"source":["encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n","encoder_model.summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"functional_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, None, 75)]        0         \n","_________________________________________________________________\n","lstm (LSTM)                  [(None, 256), (None, 256) 339968    \n","=================================================================\n","Total params: 339,968\n","Trainable params: 339,968\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U_FlFWOYSXeJ","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"ok","timestamp":1600603884060,"user_tz":-540,"elapsed":66495,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"626a40c9-3b22-4cad-b777-9c6e4c264dae"},"source":["# 이전 시점의 상태들을 저장하는 텐서\n","decoder_state_input_h = Input(shape=(256,))\n","decoder_state_input_c = Input(shape=(256,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n","decoder_states = [state_h, state_c]\n","# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n","decoder_outputs = decoder_softmax_layer(decoder_outputs)\n","decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n","decoder_model.summary()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Model: \"functional_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, None, 912)]  0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 256),  1197056     input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","                                                                 input_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 912)    234384      lstm_1[1][0]                     \n","==================================================================================================\n","Total params: 1,431,440\n","Trainable params: 1,431,440\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lvQcWFG3SXeN","colab":{},"executionInfo":{"status":"ok","timestamp":1600603884063,"user_tz":-540,"elapsed":66496,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["index_to_src = dict((i, char) for char, i in src_to_index.items())\n","index_to_tar = dict((i, char) for char, i in tar_to_index.items())"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sGw6UlqzSXeQ","colab":{},"executionInfo":{"status":"ok","timestamp":1600603884066,"user_tz":-540,"elapsed":66497,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["def decode_sequence(input_seq):\n","    # 입력으로부터 인코더의 상태를 얻음\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # <SOS>에 해당하는 원-핫 벡터 생성\n","    target_seq = np.zeros((1, 1, tar_vocab_size))\n","    target_seq[0, 0, tar_to_index['\\t']] = 1.\n","\n","    stop_condition = False\n","    decoded_sentence = \"\"\n","\n","    # stop_condition이 True가 될 때까지 루프 반복\n","    while not stop_condition:\n","        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # 예측 결과를 문자로 변환\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = index_to_tar[sampled_token_index]\n","\n","        # 현재 시점의 예측 문자를 예측 문장에 추가\n","        decoded_sentence += sampled_char\n","\n","        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_tar_len):\n","            stop_condition = True\n","\n","        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n","        target_seq = np.zeros((1, 1, tar_vocab_size))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7hD5leU5SXeU","colab":{"base_uri":"https://localhost:8080/","height":689},"executionInfo":{"status":"ok","timestamp":1600603888588,"user_tz":-540,"elapsed":71010,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"e621dfc7-5ff5-48eb-dd45-45213334c50a"},"source":["import random\n","for i in range(10): # 입력 문장의 인덱스\n","    seq_index = random.randint(10,300)\n","    input_seq = encoder_input[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print(35 * \"-\")\n","    print('입력 문장:', lines.src[seq_index])\n","    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n","    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"],"execution_count":24,"outputs":[{"output_type":"stream","text":["-----------------------------------\n","입력 문장: Step aside.\n","정답 문장:  옆으로 비켜. \n","번역기가 번역한 문장:  그만 그만해. \n","-----------------------------------\n","입력 문장: Sing along.\n","정답 문장:  따라 불러. \n","번역기가 번역한 문장:  그만 사람해. \n","-----------------------------------\n","입력 문장: Shoot!\n","정답 문장:  쏴! \n","번역기가 번역한 문장:  가져. \n","-----------------------------------\n","입력 문장: It hurts.\n","정답 문장:  아파. \n","번역기가 번역한 문장:  아파. \n","-----------------------------------\n","입력 문장: We try.\n","정답 문장:  우리는 시도할거야. \n","번역기가 번역한 문장:  우리는 거짓말 하지 마. \n","-----------------------------------\n","입력 문장: Relax.\n","정답 문장:  진정해. \n","번역기가 번역한 문장:  가져. \n","-----------------------------------\n","입력 문장: Who cares?\n","정답 문장:  누가 신경써? \n","번역기가 번역한 문장:  이렇게 짜증증수가 수가! \n","-----------------------------------\n","입력 문장: You tried.\n","정답 문장:  가상해. \n","번역기가 번역한 문장:  아무도 내 없어. \n","-----------------------------------\n","입력 문장: Tom left.\n","정답 문장:  톰은 떠났어. \n","번역기가 번역한 문장:  톰이 웃었어. \n","-----------------------------------\n","입력 문장: I'm sorry.\n","정답 문장:  미안해요. \n","번역기가 번역한 문장:  나는 이 했어. \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QfxtCWA1SXeb"},"source":["## [2]  영어-프랑스어 번역기 구현 : Word-Level 번역기 만들기"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mVXArZmISXec","colab":{},"executionInfo":{"status":"ok","timestamp":1600603888592,"user_tz":-540,"elapsed":71012,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["import numpy as np\n","import re\n","import shutil\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pandas as pd\n","import os\n","import unicodedata\n","import urllib3\n","import zipfile"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"duytxDKvSXen"},"source":["### 데이터 가져오기"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VlGszwDySXes","colab":{},"executionInfo":{"status":"ok","timestamp":1600603894471,"user_tz":-540,"elapsed":76890,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["http = urllib3.PoolManager()\n","url ='http://www.manythings.org/anki/fra-eng.zip'\n","filename = 'fra-eng.zip'\n","path = os.getcwd()\n","zipfilename = os.path.join(path, filename)\n","with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n","    shutil.copyfileobj(r, out_file)\n","\n","with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n","    zip_ref.extractall(path)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jClHm6__SXe9","colab":{},"executionInfo":{"status":"ok","timestamp":1600603894472,"user_tz":-540,"elapsed":76889,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["num_samples = 33000"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9fnywYhLSXfC"},"source":["### 전처리 함수 구현"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"djhQLDurSXfD","colab":{},"executionInfo":{"status":"ok","timestamp":1600603894473,"user_tz":-540,"elapsed":76888,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["def unicode_to_ascii(s):\n","  return ''.join(c for c in unicodedata.normalize('NFD', s)\n","      if unicodedata.category(c) != 'Mn')"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j9XqiT_cSXfH","colab":{},"executionInfo":{"status":"ok","timestamp":1600603894473,"user_tz":-540,"elapsed":76886,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["def preprocess_sentence(sent):\n","    # 위에서 구현한 함수를 내부적으로 호출\n","    sent = unicode_to_ascii(sent.lower())\n","\n","    # 단어와 구두점 사이에 공백을 만듭니다.\n","    # Ex) \"he is a boy.\" => \"he is a boy .\"\n","    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n","\n","    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n","    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n","\n","    sent = re.sub(r\"\\s+\", \" \", sent)\n","    return sent"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aAiEDvMuSXfL","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600603894473,"user_tz":-540,"elapsed":76880,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"86e10115-fde0-40cd-a518-793e18e6ed6b"},"source":["# 전처리 테스트\n","en_sent = u\"Have you had dinner?\"\n","fr_sent = u\"Avez-vous déjà diné?\"\n","print(preprocess_sentence(en_sent))\n","print(preprocess_sentence(fr_sent).encode('utf-8'))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["have you had dinner ?\n","b'avez vous deja dine ?'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Dbl0tj8zSXfU","colab":{},"executionInfo":{"status":"ok","timestamp":1600603894474,"user_tz":-540,"elapsed":76880,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["def load_preprocessed_data():\n","    encoder_input, decoder_input, decoder_target = [], [], []\n","\n","    with open(\"fra.txt\", \"r\", encoding='utf-8') as lines:\n","        for i, line in enumerate(lines):\n","\n","            # source 데이터와 target 데이터 분리\n","            src_line, tar_line, _ = line.strip().split('\\t')\n","\n","            # source 데이터 전처리\n","            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n","\n","            # target 데이터 전처리\n","            tar_line = preprocess_sentence(tar_line)\n","            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n","            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n","\n","            encoder_input.append(src_line_input)\n","            decoder_input.append(tar_line_input)\n","            decoder_target.append(tar_line_target)\n","\n","            if i == num_samples - 1:\n","                break\n","\n","    return encoder_input, decoder_input, decoder_target"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Bd7jDPPkSXfY","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1600603895484,"user_tz":-540,"elapsed":77883,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"3b43ff0b-b5c6-41b5-a8c5-e5587fc9b7a6"},"source":["sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n","print(sents_en_in[:5])\n","print(sents_fra_in[:5])\n","print(sents_fra_out[:5])"],"execution_count":32,"outputs":[{"output_type":"stream","text":["[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n","[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n","[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J2Hxz5pUSXfi"},"source":["#### 토큰화"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"es3dTrL1SXfq","colab":{},"executionInfo":{"status":"ok","timestamp":1600603895929,"user_tz":-540,"elapsed":78327,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["tokenizer_en = Tokenizer(filters=\"\", lower=False)\n","tokenizer_en.fit_on_texts(sents_en_in)\n","encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n","\n","tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n","tokenizer_fra.fit_on_texts(sents_fra_in)\n","tokenizer_fra.fit_on_texts(sents_fra_out)\n","decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n","decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fBhfzlH1SXfu"},"source":["#### 패딩"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jP0D9FZySXfv","colab":{},"executionInfo":{"status":"ok","timestamp":1600603896342,"user_tz":-540,"elapsed":78738,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["encoder_input = pad_sequences(encoder_input, padding=\"post\")\n","decoder_input = pad_sequences(decoder_input, padding=\"post\")\n","decoder_target = pad_sequences(decoder_target, padding=\"post\")"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z3kyuPD-SXf1","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603896343,"user_tz":-540,"elapsed":78733,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"4dcb0408-018a-4fbd-c4d5-b7d7be6b5886"},"source":["src_vocab_size = len(tokenizer_en.word_index) + 1\n","tar_vocab_size = len(tokenizer_fra.word_index) + 1\n","print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["영어 단어 집합의 크기 : 4663, 프랑스어 단어 집합의 크기 : 8038\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KWzfxQbYSXf8","colab":{},"executionInfo":{"status":"ok","timestamp":1600603896344,"user_tz":-540,"elapsed":78732,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["src_to_index = tokenizer_en.word_index\n","index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n","\n","tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n","index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Wl9N3ftKSXf_","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603896345,"user_tz":-540,"elapsed":78727,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"4603879c-8e35-4d4a-ef12-1e2f63dc7767"},"source":["indices = np.arange(encoder_input.shape[0])\n","np.random.shuffle(indices)\n","print(indices)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["[25478  7560 30953 ... 21972 16195 14914]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MscryFXZSXgC","colab":{},"executionInfo":{"status":"ok","timestamp":1600603896346,"user_tz":-540,"elapsed":78726,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["encoder_input = encoder_input[indices]\n","decoder_input = decoder_input[indices]\n","decoder_target = decoder_target[indices]"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iuoXjYvBSXgH","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603896348,"user_tz":-540,"elapsed":78721,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"2c816118-198f-47dc-8dc8-ab57a4dc3b13"},"source":["encoder_input[30997]"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  2,  13, 480,  17,  36,  88,   1,   0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ylXNo1iPSXgM","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600603896349,"user_tz":-540,"elapsed":78715,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"03b3f423-72fb-48e8-b549-a5397e8d7e1d"},"source":["decoder_input[30997]"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  2,   4,  21, 398,  37,  83,   8,  22, 105,   1,   0,   0,   0,\n","         0,   0,   0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zon8h9h9SXgQ","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600603896350,"user_tz":-540,"elapsed":78710,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"2b6a2a08-6d99-47ac-fc93-326402b1e6da"},"source":["decoder_target[30997]"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  4,  21, 398,  37,  83,   8,  22, 105,   1,   3,   0,   0,   0,\n","         0,   0,   0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tQGEva6bSXgU","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600603896351,"user_tz":-540,"elapsed":78705,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"3d39911d-7c9b-4686-ea48-e8d7f31575de"},"source":["n_of_val = int(33000*0.1)\n","print(n_of_val)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["3300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-ARpbCn4SXgd","colab":{},"executionInfo":{"status":"ok","timestamp":1600603896352,"user_tz":-540,"elapsed":78704,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["encoder_input_train = encoder_input[:-n_of_val]\n","decoder_input_train = decoder_input[:-n_of_val]\n","decoder_target_train = decoder_target[:-n_of_val]\n","\n","encoder_input_test = encoder_input[-n_of_val:]\n","decoder_input_test = decoder_input[-n_of_val:]\n","decoder_target_test = decoder_target[-n_of_val:]"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"st2rgSm9SXgr","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1600603896353,"user_tz":-540,"elapsed":78698,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"8a0a2379-cd21-4458-c6ba-41f07b3b4b22"},"source":["print(encoder_input_train.shape)\n","print(decoder_input_train.shape)\n","print(decoder_target_train.shape)\n","print(encoder_input_test.shape)\n","print(decoder_input_test.shape)\n","print(decoder_target_test.shape)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["(29700, 8)\n","(29700, 16)\n","(29700, 16)\n","(3300, 8)\n","(3300, 16)\n","(3300, 16)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j1BdjcAaSXg3"},"source":["### 기계 번역기 구현"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o2WxuRICSXg4","colab":{},"executionInfo":{"status":"ok","timestamp":1600603896353,"user_tz":-540,"elapsed":78696,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n","from tensorflow.keras.models import Model"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FYOGyGqMSXg_","colab":{},"executionInfo":{"status":"ok","timestamp":1600603896354,"user_tz":-540,"elapsed":78696,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["latent_dim = 50"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YAEZxvTuSXhW","colab":{},"executionInfo":{"status":"ok","timestamp":1600603897274,"user_tz":-540,"elapsed":79614,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["# 인코더\n","encoder_inputs = Input(shape=(None,))\n","enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n","enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n","encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n","encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n","encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ihOOi1DYSXhm","colab":{},"executionInfo":{"status":"ok","timestamp":1600603897947,"user_tz":-540,"elapsed":80285,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["# 디코더\n","decoder_inputs = Input(shape=(None,))\n","dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n","dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n","dec_masking = Masking(mask_value=0.0)(dec_emb)\n","\n","# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n","\n","# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n","decoder_outputs, _, _ = decoder_lstm(dec_masking,\n","                                     initial_state=encoder_states)\n","\n","# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n","decoder_dense = Dense(tar_vocab_size, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PutYscpySXiF","colab":{},"executionInfo":{"status":"ok","timestamp":1600603897949,"user_tz":-540,"elapsed":80285,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"by8ylCE5SXiR","colab":{},"executionInfo":{"status":"ok","timestamp":1600603897951,"user_tz":-540,"elapsed":80285,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UQ99SOjvSXiZ","colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"status":"ok","timestamp":1600603897953,"user_tz":-540,"elapsed":80281,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"3a135a28-42aa-4829-b4f7-3885e738840f"},"source":["model.summary()"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Model: \"functional_7\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, None, 50)     233150      input_5[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 50)     401900      input_6[0][0]                    \n","__________________________________________________________________________________________________\n","masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n","__________________________________________________________________________________________________\n","masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, 50), (None,  20200       masking[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_3 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n","                                                                 lstm_2[0][1]                     \n","                                                                 lstm_2[0][2]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 8038)   409938      lstm_3[0][0]                     \n","==================================================================================================\n","Total params: 1,085,388\n","Trainable params: 1,085,388\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V6ND8EyXSXic","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"ok","timestamp":1600604031440,"user_tz":-540,"elapsed":213762,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"410a6358-56a4-47fb-beae-855bf18d6c43"},"source":["model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n","          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n","          batch_size = 128, epochs = 10)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","233/233 [==============================] - 13s 55ms/step - loss: 3.2035 - acc: 0.6079 - val_loss: 1.9200 - val_acc: 0.6808\n","Epoch 2/10\n","233/233 [==============================] - 13s 54ms/step - loss: 1.7269 - acc: 0.7272 - val_loss: 1.6753 - val_acc: 0.7345\n","Epoch 3/10\n","233/233 [==============================] - 13s 55ms/step - loss: 1.5572 - acc: 0.7472 - val_loss: 1.5560 - val_acc: 0.7477\n","Epoch 4/10\n","233/233 [==============================] - 12s 52ms/step - loss: 1.4616 - acc: 0.7603 - val_loss: 1.4607 - val_acc: 0.7648\n","Epoch 5/10\n","233/233 [==============================] - 12s 52ms/step - loss: 1.3781 - acc: 0.7743 - val_loss: 1.3894 - val_acc: 0.7758\n","Epoch 6/10\n","233/233 [==============================] - 12s 54ms/step - loss: 1.3052 - acc: 0.7863 - val_loss: 1.3387 - val_acc: 0.7823\n","Epoch 7/10\n","233/233 [==============================] - 13s 56ms/step - loss: 1.2463 - acc: 0.7952 - val_loss: 1.2886 - val_acc: 0.7923\n","Epoch 8/10\n","233/233 [==============================] - 13s 56ms/step - loss: 1.1981 - acc: 0.8026 - val_loss: 1.2569 - val_acc: 0.7979\n","Epoch 9/10\n","233/233 [==============================] - 13s 55ms/step - loss: 1.1568 - acc: 0.8089 - val_loss: 1.2182 - val_acc: 0.8039\n","Epoch 10/10\n","233/233 [==============================] - 13s 56ms/step - loss: 1.1217 - acc: 0.8138 - val_loss: 1.1877 - val_acc: 0.8086\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f36be814550>"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BRFitd6SSXio","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"ok","timestamp":1600604031441,"user_tz":-540,"elapsed":213755,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"be7b5504-ba91-4aa3-f3a0-4f262b16400d"},"source":["# 인코더\n","encoder_model = Model(encoder_inputs, encoder_states)\n","encoder_model.summary()"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Model: \"functional_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, None)]            0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, None, 50)          233150    \n","_________________________________________________________________\n","masking (Masking)            (None, None, 50)          0         \n","_________________________________________________________________\n","lstm_2 (LSTM)                [(None, 50), (None, 50),  20200     \n","=================================================================\n","Total params: 253,350\n","Trainable params: 253,350\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LrpZfgBLSXiq","colab":{},"executionInfo":{"status":"ok","timestamp":1600604031442,"user_tz":-540,"elapsed":213754,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["# 디코더\n","# 이전 시점의 상태를 보관할 텐서\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# 훈련 때 사용했던 임베딩 층을 재사용\n","dec_emb2= dec_emb_layer(decoder_inputs)\n","\n","# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n","decoder_states2 = [state_h2, state_c2]\n","\n","# 모든 시점에 대해서 단어 예측\n","decoder_outputs2 = decoder_dense(decoder_outputs2)"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qjGeNSQXSXiy","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1600604031442,"user_tz":-540,"elapsed":213748,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"b43eb8f2-7c3a-44a9-c687-cb0ef11fc7ce"},"source":["decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs2] + decoder_states2)\n","decoder_model.summary()"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Model: \"functional_11\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 50)     401900      input_6[0][0]                    \n","__________________________________________________________________________________________________\n","input_7 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","input_8 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","lstm_3 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[1][0]                \n","                                                                 input_7[0][0]                    \n","                                                                 input_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 8038)   409938      lstm_3[1][0]                     \n","==================================================================================================\n","Total params: 832,038\n","Trainable params: 832,038\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"97dC1yUXSXjM","colab":{},"executionInfo":{"status":"ok","timestamp":1600604031819,"user_tz":-540,"elapsed":214123,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["def decode_sequence(input_seq):\n","    # 입력으로부터 인코더의 상태를 얻음\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # <SOS>에 해당하는 정수 생성\n","    target_seq = np.zeros((1,1))\n","    target_seq[0, 0] = tar_to_index['<sos>']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","\n","    # stop_condition이 True가 될 때까지 루프 반복\n","    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n","    while not stop_condition:\n","        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # 예측 결과를 단어로 변환\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = index_to_tar[sampled_token_index]\n","\n","         # 현재 시점의 예측 단어를 예측 문장에 추가\n","        decoded_sentence += ' '+sampled_char\n","\n","        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n","        if (sampled_char == '<eos>' or\n","           len(decoded_sentence) > 50):\n","            stop_condition = True\n","\n","        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n","        target_seq = np.zeros((1,1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kGsOWsQqSXje","colab":{},"executionInfo":{"status":"ok","timestamp":1600604031822,"user_tz":-540,"elapsed":214124,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":["# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq2src(input_seq):\n","    temp=''\n","    for i in input_seq:\n","        if(i!=0):\n","            temp = temp + index_to_src[i]+' '\n","    return temp\n","\n","# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq2tar(input_seq):\n","    temp=''\n","    for i in input_seq:\n","        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n","            temp = temp + index_to_tar[i] + ' '\n","    return temp"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rkIGwcv9SXjr","colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"status":"ok","timestamp":1600604033864,"user_tz":-540,"elapsed":216160,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"99bfbddf-d59c-4a01-9500-6dfe4de93c11"},"source":["for seq_index in [3,50,100,300,1001]:\n","  input_seq = encoder_input_train[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","\n","  print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n","  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n","  print(\"예측문 :\",decoded_sentence[:-5])\n","  print(\"\\n\")"],"execution_count":58,"outputs":[{"output_type":"stream","text":["원문 :  why is snow white ? \n","번역문 : pourquoi la neige est elle blanche ? \n","예측문 :  ou est ce que ca est ? \n","\n","\n","원문 :  tom are you awake ? \n","번역문 : tom etes vous reveille ? \n","예측문 :  ils ce que tom est ? \n","\n","\n","원문 :  tom s guilty . \n","번역문 : tom est coupable . \n","예측문 :  tom est . \n","\n","\n","원문 :  he fooled her . \n","번역문 : il la dupa . \n","예측문 :  il a l air . \n","\n","\n","원문 :  we both love you . \n","번역문 : nous vous aimons tous les deux . \n","예측문 :  nous avons ete tres . \n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lmVTBcoUSXjt","colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"status":"ok","timestamp":1600604035773,"user_tz":-540,"elapsed":218063,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}},"outputId":"1224b5e7-5243-4691-a01a-459df1692ae3"},"source":["for seq_index in [3,50,100,300,1001]:\n","  input_seq = encoder_input_test[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","\n","  print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n","  print(\"번역문 :\",seq2tar(decoder_input_test[seq_index]))\n","  print(\"예측문 :\",decoded_sentence[:-5])\n","  print(\"\\n\")"],"execution_count":59,"outputs":[{"output_type":"stream","text":["원문 :  hi guys . \n","번역문 : salut les mecs ! \n","예측문 :  arrete de nous ! \n","\n","\n","원문 :  i smelled it . \n","번역문 : je l ai sentie . \n","예측문 :  je me suis en train de aller . \n","\n","\n","원문 :  do you see a star ? \n","번역문 : est ce que tu vois une etoile ? \n","예측문 :  est ce que tu ? \n","\n","\n","원문 :  she ll be just fine . \n","번역문 : ca ira tres bien pour elle . \n","예측문 :  elle a l air ete . \n","\n","\n","원문 :  can you believe it ? \n","번역문 : pouvez vous le croire ? \n","예측문 :  puis je vous veux ? \n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5ls7-3rySXjv","colab":{},"executionInfo":{"status":"ok","timestamp":1600604035774,"user_tz":-540,"elapsed":218062,"user":{"displayName":"고병화","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64","userId":"12645007744594631320"}}},"source":[""],"execution_count":59,"outputs":[]}]}