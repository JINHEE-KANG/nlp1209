{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 사용 문장생성 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nn_layers import softmax,TimeDropout,Rnnlm,BetterRnnlm,RnnlmTrainer\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):  # sample_size : 샘플링하는 단어의 수\n",
    "        word_ids = [start_id]  # start_id : 최초로 시작할 단어\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())  # 10000개의 단어의 각각의 확률을 구함\n",
    "            # print('p.shape:',p.shape) # (10000,)\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p) # 확률 분포를 사용하여 random으로 1개의 단어 샘플링, 확률적 방법\n",
    "            \n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x)) # word_ids 리스트에 샘플링된 단어를 추가\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "\n",
    "\n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장생성을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you restoration recalled responding outstanding clean-air smallest lined eddie pleasure odeon backlogs marcos parker cast predicting soap worry businessman scripts appellate institutions entitled neuberger softening nomura seven refined jenrette fat sorrell traveled appointed dec. festival quarter basin november throws waves units princeton social made dioxide olympic berlitz provides enforce did flush morrison summoned termed widely soviet defending maintained creatures quotas boren met sailing caterpillar contrary eight cater watches convenience triggering daiwa complex backlash legislatures capped bracing architecture probable birds sustain finkelstein pursue stopped bran out buying roughly career whether murray mountain-bike minds paso ciba-geigy stevens strongly cases goodman thoughts lender\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params('Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]  # 전처리된 단어를 제외\n",
    "\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids,100)  # 사직할 단어의 id와 제외할 단어 id를 입력하여 100개의 단어 샘플링\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])  # 100개의 단어를 한 문장으로 연결 \n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)  # 실행시 마다 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 좋은 문장으로 : 2층 LSTM,  Dropout, 가중치 공유 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you makers allegations prominent falls andreas adjusting boy infiniti mackenzie pbs leased trustcorp literature commitment fundamentally farms fred excess lbo s.p proposing cases stops tax-loss schools partial xerox implied mellon supporting queen australia h. anti-drug guilders leipzig sagan replies counted rudolph undisclosed changed institution residents adding impetus ohbayashi high bond kurt over units threatening opens channels fundamental oust murata key illustrates battled performance reputable billion rows cox folk aborted debentures minicomputers herself liabilities mistakes landscape fate lack words sign railway catalog motor scheduled character merchandising concept supply carl distribute lionel backers pentagon unsuccessfully cruise coke sticking proposed cent economics bring\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "model.load_params('BetterRnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어열을 초기 값으로 주고 문장을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the meaning of life is refunding ddb horse forming shortages victories intelligence crossing all otc curbing buick underground located pointed azt roh previous damaged member race know-how update battered quantities degree arrived kan. samuel isolated hurting existing itself shadow sessions improperly james planner v. everyone batch rain steer areas best-known guess banxquote printer 19th greenspan ken carpenter pa debenture downright lighting crumbling luck khan fight upset acquisitions adults indicated four-year-old canadian creek whooping suddenly opportunities calendar published coupon softening violence sorts welcome dumped tritium tumultuous succeeded sutton briefing design czechoslovakia probably arctic occasion surrender furs obliged pain backed nationwide anxiety innovation wilbur believe inning\n"
     ]
    }
   ],
   "source": [
    "model.reset_state()\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "# print(start_ids)\n",
    "\n",
    "# 'the meaning of life' 부분 예측  :  'meaning of life is' 으로 예측 되지 않음\n",
    "# for x in start_ids[:-1]:\n",
    "#     x = np.array(x).reshape(1, 1)\n",
    "#     score = model.predict(x).flatten()\n",
    "#     p = softmax(score).flatten()\n",
    "#     sampled = np.random.choice(len(p), size=1, p=p)\n",
    "#     print(sampled)\n",
    "\n",
    "word_ids = model.generate(start_ids[-1], skip_ids)  # 마지막 단어('is')를 시작 단어로 문장 생성\n",
    "word_ids = start_ids[:-1] + word_ids                # 'is' 앞까지의 단어를 앞부분에 추가\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)  #  실행시 마다 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
